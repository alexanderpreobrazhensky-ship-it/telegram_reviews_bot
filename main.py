import os
import re
import json
import time
import csv
import io
import hashlib
import logging
import threading
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional, Tuple

import requests
from flask import Flask, request, jsonify

# -----------------------------
# Logging
# -----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("telegram_reviews_bot")

# -----------------------------
# OpenAI SDK (required for DeepSeek gateways)
# -----------------------------
try:
    from openai import OpenAI  # type: ignore
    OPENAI_SDK_AVAILABLE = True
except Exception:
    OPENAI_SDK_AVAILABLE = False
    OpenAI = None  # type: ignore

# -----------------------------
# Env / Config
# -----------------------------
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN") or os.getenv("TELEGRAM_TOKEN")
if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN (or TELEGRAM_TOKEN) is required")

WEBHOOK_URL = os.getenv("WEBHOOK_URL")
if not WEBHOOK_URL:
    raise ValueError("WEBHOOK_URL is required (e.g. https://xxx.up.railway.app)")

# secret part of webhook path (hook123)
BOT_PATH_SECRET = os.getenv("BOT_PATH_SECRET", "").strip()
if not BOT_PATH_SECRET:
    # fallback: last 12 chars of token (not ideal, but prevents 404)
    BOT_PATH_SECRET = TELEGRAM_BOT_TOKEN[-12:]
    logger.warning("BOT_PATH_SECRET not set. Using fallback based on token suffix.")

WEBHOOK_PATH = f"/webhook/{BOT_PATH_SECRET}"
WEBHOOK_FULL_URL = f"{WEBHOOK_URL.rstrip('/')}{WEBHOOK_PATH}"

PORT = int(os.getenv("PORT", "8000"))

AI_ENGINE = (os.getenv("AI_ENGINE") or "deepseek").strip().lower()  # default deepseek
CX_PROMPT_MODE = (os.getenv("CX_PROMPT_MODE") or "full").strip().lower()  # full|lite

# DeepSeek / Artemox
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY") or os.getenv("DEEPSEEK_KEY")
DEEPSEEK_BASE_URL = (os.getenv("DEEPSEEK_BASE_URL") or "https://api.artemox.com/v1").rstrip("/")
DEEPSEEK_MODEL = os.getenv("DEEPSEEK_MODEL") or "deepseek-chat"
DEEPSEEK_URL = f"{DEEPSEEK_BASE_URL}/chat/completions"

# OPTIONAL: allow requests fallback (Cloudflare sometimes blocks it)
DEEPSEEK_ALLOW_REQUESTS_FALLBACK = (os.getenv("DEEPSEEK_ALLOW_REQUESTS_FALLBACK") or "0").strip() == "1"

# OpenAI (optional)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = (os.getenv("OPENAI_BASE_URL") or "https://api.openai.com/v1").rstrip("/")
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or "gpt-4o-mini"

# Gemini (optional)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL") or "gemini-2.0-flash"
GEMINI_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"

# Grok/xAI placeholder (optional)
GROK_API_KEY = os.getenv("GROK_API_KEY")
GROK_BASE_URL = (os.getenv("GROK_BASE_URL") or "").rstrip("/")
GROK_MODEL = os.getenv("GROK_MODEL") or "grok-beta"

# Admin allowlist: comma-separated chat_ids
REPORT_CHAT_IDS = os.getenv("REPORT_CHAT_IDS", "").strip()
ADMIN_CHAT_IDS: List[int] = []
if REPORT_CHAT_IDS:
    for x in REPORT_CHAT_IDS.split(","):
        x = x.strip()
        if x:
            try:
                ADMIN_CHAT_IDS.append(int(x))
            except Exception:
                pass

ADMIN_MODE = "allowlist" if ADMIN_CHAT_IDS else "closed"

# DB
DATABASE_URL = os.getenv("DATABASE_URL") or os.getenv("DATABASE_PUBLIC_URL") or os.getenv("DATABASE_URL_INTERNAL")

# Cron token (protect /cron/weekly)
CRON_TOKEN = os.getenv("CRON_TOKEN", "").strip()

# Diagnostics token (optional) - if set, /diag/ai requires ?token=
DIAG_TOKEN = os.getenv("DIAG_TOKEN", "").strip()

# Timeouts
TG_TIMEOUT = float(os.getenv("TG_TIMEOUT", "10"))
AI_TIMEOUT = float(os.getenv("AI_TIMEOUT", "40"))

# -----------------------------
# Flask
# -----------------------------
app = Flask(__name__)

# -----------------------------
# Redaction
# -----------------------------
def _redact(s: str) -> str:
    if not s:
        return s
    s = s.replace(TELEGRAM_BOT_TOKEN, "***TG_TOKEN***")
    if DEEPSEEK_API_KEY:
        s = s.replace(DEEPSEEK_API_KEY, "***DEEPSEEK_KEY***")
    if OPENAI_API_KEY:
        s = s.replace(OPENAI_API_KEY, "***OPENAI_KEY***")
    if GEMINI_API_KEY:
        s = s.replace(GEMINI_API_KEY, "***GEMINI_KEY***")
    if GROK_API_KEY:
        s = s.replace(GROK_API_KEY, "***GROK_KEY***")
    return s

# -----------------------------
# Telegram helpers
# -----------------------------
def tg_api(method: str) -> str:
    return f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/{method}"

def send_message(chat_id: int, text: str, reply_markup: Optional[dict] = None, parse_mode: Optional[str] = None) -> None:
    payload = {"chat_id": chat_id, "text": text}
    if parse_mode:
        payload["parse_mode"] = parse_mode
    if reply_markup:
        payload["reply_markup"] = reply_markup
    try:
        r = requests.post(tg_api("sendMessage"), json=payload, timeout=TG_TIMEOUT)
        if r.status_code != 200:
            logger.error("sendMessage failed status=%s body=%s", r.status_code, _redact(r.text[:900]))
    except Exception as e:
        logger.exception("sendMessage exception: %s", e)

def answer_callback_query(callback_query_id: str, text: str = "", show_alert: bool = False) -> None:
    payload = {"callback_query_id": callback_query_id, "text": text, "show_alert": show_alert}
    try:
        r = requests.post(tg_api("answerCallbackQuery"), json=payload, timeout=TG_TIMEOUT)
        if r.status_code != 200:
            logger.error("answerCallbackQuery failed status=%s body=%s", r.status_code, _redact(r.text[:500]))
    except Exception:
        logger.exception("answerCallbackQuery exception")

def send_document(chat_id: int, filename: str, content: bytes) -> None:
    files = {"document": (filename, content)}
    data = {"chat_id": chat_id}
    try:
        r = requests.post(tg_api("sendDocument"), data=data, files=files, timeout=TG_TIMEOUT)
        if r.status_code != 200:
            logger.error("sendDocument failed status=%s body=%s", r.status_code, _redact(r.text[:900]))
    except Exception:
        logger.exception("sendDocument exception")

def _is_admin(user_id: Optional[int], chat_id: Optional[int] = None) -> bool:
    """
    Admin allowlist contains IDs. In private chats user_id==chat_id, but in groups they differ.
    So we allow either match.
    """
    if not ADMIN_CHAT_IDS:
        return False  # strict admin-only
    if user_id is not None and user_id in ADMIN_CHAT_IDS:
        return True
    if chat_id is not None and chat_id in ADMIN_CHAT_IDS:
        return True
    return False

def _display_name(user: dict) -> str:
    username = (user.get("username") or "").strip()
    first_name = (user.get("first_name") or "").strip()
    if username:
        return f"@{username}"
    if first_name:
        return first_name
    return "–¥—Ä—É–≥"

# -----------------------------
# Webhook setup (per process)
# -----------------------------
_webhook_set_once = False
_webhook_lock = threading.Lock()

def set_webhook_once() -> None:
    global _webhook_set_once
    with _webhook_lock:
        if _webhook_set_once:
            return
        _webhook_set_once = True

    try:
        logger.info("Setting webhook: %s", WEBHOOK_FULL_URL)
        r = requests.get(
            tg_api("setWebhook"),
            params={"url": WEBHOOK_FULL_URL},
            timeout=TG_TIMEOUT,
        )
        if r.status_code == 200:
            logger.info("setWebhook OK: %s", _redact(r.text[:500]))
        elif r.status_code == 429:
            logger.warning("setWebhook got 429 (ignored): %s", _redact(r.text[:500]))
        else:
            logger.error("setWebhook failed status=%s body=%s", r.status_code, _redact(r.text[:900]))
    except Exception:
        logger.exception("setWebhook exception")

# -----------------------------
# DB layer (psycopg v3 recommended)
# -----------------------------
DB_OK = False

def _db_connect():
    """
    Returns psycopg connection, or None if not configured.
    """
    if not DATABASE_URL:
        return None
    try:
        import psycopg  # type: ignore
        conn = psycopg.connect(DATABASE_URL, autocommit=True)
        return conn
    except Exception as e:
        logger.error("DB connect failed: %s", e)
        return None

def db_init() -> None:
    """
    IMPORTANT: Do NOT rely on CREATE TABLE IF NOT EXISTS for schema changes.
    Existing DB may have old schema. We do safe migrations via ADD COLUMN IF NOT EXISTS.
    """
    global DB_OK
    conn = _db_connect()
    if not conn:
        DB_OK = False
        logger.warning("DB init skipped (DATABASE_URL not set or connect failed)")
        return

    try:
        with conn.cursor() as cur:
            # Baseline tables (minimal)
            cur.execute("CREATE TABLE IF NOT EXISTS reviews (id BIGSERIAL PRIMARY KEY);")
            cur.execute("CREATE TABLE IF NOT EXISTS review_analyses (id BIGSERIAL PRIMARY KEY);")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS settings (
                    key TEXT PRIMARY KEY,
                    value JSONB NOT NULL DEFAULT '{}'::jsonb,
                    updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
                );
            """)
            cur.execute("""
                CREATE TABLE IF NOT EXISTS user_sessions (
                    chat_id BIGINT PRIMARY KEY,
                    state TEXT NOT NULL,
                    payload JSONB NOT NULL DEFAULT '{}'::jsonb,
                    updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
                );
            """)

            # Migrate reviews
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS platform TEXT;")
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS source TEXT NOT NULL DEFAULT 'manual';")
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS rating INT;")
            # FIX: this column was missing in your production DB
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS review_text TEXT;")
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS review_hash TEXT;")
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS meta JSONB NOT NULL DEFAULT '{}'::jsonb;")
            cur.execute("ALTER TABLE reviews ADD COLUMN IF NOT EXISTS created_at TIMESTAMPTZ NOT NULL DEFAULT now();")

            # Migrate review_analyses
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS review_id BIGINT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS platform TEXT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS rating INT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS review_text TEXT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS result_json JSONB NOT NULL DEFAULT '{}'::jsonb;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS error TEXT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS model TEXT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS engine TEXT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS created_by BIGINT;")
            cur.execute("ALTER TABLE review_analyses ADD COLUMN IF NOT EXISTS created_at TIMESTAMPTZ NOT NULL DEFAULT now();")

            # Ensure unique index on review_id (best-effort)
            try:
                cur.execute("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (
                            SELECT 1
                            FROM pg_indexes
                            WHERE schemaname = 'public'
                              AND tablename = 'review_analyses'
                              AND indexname = 'review_analyses_review_id_uniq'
                        ) THEN
                            CREATE UNIQUE INDEX review_analyses_review_id_uniq ON review_analyses (review_id);
                        END IF;
                    END$$;
                """)
            except Exception:
                pass

        DB_OK = True
        logger.info("DB init OK (postgres=True)")
    except Exception:
        DB_OK = False
        logger.exception("DB init failed")
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_insert_review(source: str, rating: Optional[int], review_text: str, meta: dict,
                     platform: Optional[str] = None, review_hash: Optional[str] = None) -> Optional[int]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO reviews (source, rating, review_text, meta, platform, review_hash)
                VALUES (%s, %s, %s, %s::jsonb, %s, %s)
                RETURNING id
                """,
                (source, rating, review_text, json.dumps(meta, ensure_ascii=False), platform, review_hash),
            )
            row = cur.fetchone()
            return int(row[0]) if row else None
    except Exception:
        logger.exception("db_insert_review failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_review(review_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT id, source, rating, review_text, meta, created_at, platform, review_hash FROM reviews WHERE id=%s", (review_id,))
            row = cur.fetchone()
            if not row:
                return None
            return {
                "id": int(row[0]),
                "source": row[1],
                "rating": row[2],
                "review_text": row[3],
                "meta": row[4] if isinstance(row[4], dict) else (json.loads(row[4]) if row[4] else {}),
                "created_at": str(row[5]),
                "platform": row[6],
                "review_hash": row[7],
            }
    except Exception:
        logger.exception("db_get_review failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_list_reviews(n: int = 10, source: Optional[str] = None) -> List[dict]:
    conn = _db_connect()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            if source:
                cur.execute(
                    "SELECT id, source, rating, left(review_text, 140), created_at, platform FROM reviews WHERE source=%s ORDER BY id DESC LIMIT %s",
                    (source, n),
                )
            else:
                cur.execute(
                    "SELECT id, source, rating, left(review_text, 140), created_at, platform FROM reviews ORDER BY id DESC LIMIT %s",
                    (n,),
                )
            rows = cur.fetchall() or []
            out = []
            for r in rows:
                out.append({
                    "id": int(r[0]),
                    "source": r[1],
                    "rating": r[2],
                    "preview": r[3],
                    "created_at": str(r[4]),
                    "platform": r[5],
                })
            return out
    except Exception:
        logger.exception("db_list_reviews failed")
        return []
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_delete_review(review_id: int) -> bool:
    conn = _db_connect()
    if not conn:
        return False
    try:
        with conn.cursor() as cur:
            cur.execute("DELETE FROM reviews WHERE id=%s", (review_id,))
        return True
    except Exception:
        logger.exception("db_delete_review failed")
        return False
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_insert_analysis(
    review_id: Optional[int],
    platform: Optional[str],
    rating: Optional[int],
    review_text: str,
    result_json: dict,
    error: Optional[str],
    model: str,
    engine: str,
    created_by: Optional[int],
) -> Optional[int]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            if review_id is not None:
                cur.execute(
                    """
                    INSERT INTO review_analyses
                    (review_id, platform, rating, review_text, result_json, error, model, engine, created_by)
                    VALUES (%s,%s,%s,%s,%s::jsonb,%s,%s,%s,%s)
                    ON CONFLICT (review_id)
                    DO UPDATE SET
                        platform=EXCLUDED.platform,
                        rating=EXCLUDED.rating,
                        review_text=EXCLUDED.review_text,
                        result_json=EXCLUDED.result_json,
                        error=EXCLUDED.error,
                        model=EXCLUDED.model,
                        engine=EXCLUDED.engine,
                        created_by=EXCLUDED.created_by,
                        created_at=now()
                    RETURNING id
                    """,
                    (
                        review_id,
                        platform,
                        rating,
                        review_text,
                        json.dumps(result_json, ensure_ascii=False),
                        error,
                        model,
                        engine,
                        created_by,
                    ),
                )
            else:
                cur.execute(
                    """
                    INSERT INTO review_analyses
                    (review_id, platform, rating, review_text, result_json, error, model, engine, created_by)
                    VALUES (%s,%s,%s,%s,%s::jsonb,%s,%s,%s,%s)
                    RETURNING id
                    """,
                    (
                        review_id,
                        platform,
                        rating,
                        review_text,
                        json.dumps(result_json, ensure_ascii=False),
                        error,
                        model,
                        engine,
                        created_by,
                    ),
                )
            row = cur.fetchone()
            return int(row[0]) if row else None
    except Exception:
        logger.exception("db_insert_analysis failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_analysis(analysis_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT id, review_id, platform, rating, review_text, result_json, error, model, engine, created_by, created_at FROM review_analyses WHERE id=%s",
                (analysis_id,),
            )
            r = cur.fetchone()
            if not r:
                return None
            return {
                "id": int(r[0]),
                "review_id": r[1],
                "platform": r[2],
                "rating": r[3],
                "review_text": r[4],
                "result_json": r[5] if isinstance(r[5], dict) else (json.loads(r[5]) if r[5] else {}),
                "error": r[6],
                "model": r[7],
                "engine": r[8],
                "created_by": r[9],
                "created_at": str(r[10]),
            }
    except Exception:
        logger.exception("db_get_analysis failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_analysis_by_review_id(review_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT id, review_id, platform, rating, review_text, result_json, error, model, engine, created_by, created_at FROM review_analyses WHERE review_id=%s",
                (review_id,),
            )
            r = cur.fetchone()
            if not r:
                return None
            return {
                "id": int(r[0]),
                "review_id": r[1],
                "platform": r[2],
                "rating": r[3],
                "review_text": r[4],
                "result_json": r[5] if isinstance(r[5], dict) else (json.loads(r[5]) if r[5] else {}),
                "error": r[6],
                "model": r[7],
                "engine": r[8],
                "created_by": r[9],
                "created_at": str(r[10]),
            }
    except Exception:
        logger.exception("db_get_analysis_by_review_id failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_find_reviews(platform: Optional[str], rating: Optional[int], days: int, limit: int, offset: int) -> List[dict]:
    conn = _db_connect()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            clauses = ["created_at >= now() - (%s || ' days')::interval"]
            params: List[Any] = [days]
            if platform and platform != "all":
                clauses.append("platform = %s")
                params.append(platform)
            if rating is not None:
                clauses.append("rating = %s")
                params.append(rating)
            where = " AND ".join(clauses)
            params.extend([limit, offset])
            cur.execute(
                f"""
                SELECT id, platform, rating, left(review_text, 80), created_at
                FROM reviews
                WHERE {where}
                ORDER BY id DESC
                LIMIT %s OFFSET %s
                """,
                tuple(params),
            )
            rows = cur.fetchall() or []
            out = []
            for r in rows:
                out.append({
                    "id": int(r[0]),
                    "platform": r[1],
                    "rating": r[2],
                    "preview": r[3],
                    "created_at": str(r[4]),
                })
            return out
    except Exception:
        logger.exception("db_find_reviews failed")
        return []
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_export_reviews(days: int = 30, limit: int = 500) -> List[dict]:
    conn = _db_connect()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT
                  r.id,
                  r.created_at,
                  r.platform,
                  r.rating,
                  r.review_text,
                  a.created_at as analysis_created_at,
                  a.result_json
                FROM reviews r
                LEFT JOIN review_analyses a ON a.review_id = r.id
                WHERE r.created_at >= now() - (%s || ' days')::interval
                ORDER BY r.id DESC
                LIMIT %s
                """,
                (days, limit),
            )
            rows = cur.fetchall() or []
            out = []
            for r in rows:
                result_json = r[6] if isinstance(r[6], dict) else (json.loads(r[6]) if r[6] else {})
                sentiment = result_json.get("sentiment") or {}
                public_reply = result_json.get("public_reply") or {}
                complaint = result_json.get("complaint") or {}
                out.append({
                    "id": int(r[0]),
                    "created_at": str(r[1]),
                    "platform": r[2],
                    "rating": r[3],
                    "review_text": r[4],
                    "analysis_created_at": str(r[5]) if r[5] else None,
                    "sentiment_label": sentiment.get("label"),
                    "sentiment_score": sentiment.get("score"),
                    "public_reply_text": public_reply.get("text") if isinstance(public_reply, dict) else None,
                    "complaint_needed": complaint.get("needed") if isinstance(complaint, dict) else None,
                    "complaint_text": complaint.get("text") if isinstance(complaint, dict) else None,
                })
            return out
    except Exception:
        logger.exception("db_export_reviews failed")
        return []
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_find_duplicate_review(review_hash: str, days: int = 14) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT id, created_at
                FROM reviews
                WHERE review_hash = %s
                  AND created_at >= now() - (%s || ' days')::interval
                ORDER BY id DESC
                LIMIT 1
                """,
                (review_hash, days),
            )
            row = cur.fetchone()
            if not row:
                return None
            return {"id": int(row[0]), "created_at": str(row[1])}
    except Exception:
        logger.exception("db_find_duplicate_review failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_setting(key: str) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT value FROM settings WHERE key=%s", (key,))
            row = cur.fetchone()
            if not row:
                return None
            val = row[0]
            return val if isinstance(val, dict) else (json.loads(val) if val else {})
    except Exception:
        logger.exception("db_get_setting failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_set_setting(key: str, value: dict) -> None:
    conn = _db_connect()
    if not conn:
        return
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO settings (key, value)
                VALUES (%s, %s::jsonb)
                ON CONFLICT (key)
                DO UPDATE SET value=EXCLUDED.value, updated_at=now()
                """,
                (key, json.dumps(value, ensure_ascii=False)),
            )
    except Exception:
        logger.exception("db_set_setting failed")
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_session(chat_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT state, payload, updated_at FROM user_sessions WHERE chat_id=%s", (chat_id,))
            row = cur.fetchone()
            if not row:
                return None
            payload = row[1] if isinstance(row[1], dict) else (json.loads(row[1]) if row[1] else {})
            return {"state": row[0], "payload": payload, "updated_at": row[2]}
    except Exception:
        logger.exception("db_get_session failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_set_session(chat_id: int, state: str, payload: dict) -> None:
    conn = _db_connect()
    if not conn:
        return
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO user_sessions (chat_id, state, payload)
                VALUES (%s, %s, %s::jsonb)
                ON CONFLICT (chat_id)
                DO UPDATE SET state=EXCLUDED.state, payload=EXCLUDED.payload, updated_at=now()
                """,
                (chat_id, state, json.dumps(payload, ensure_ascii=False)),
            )
    except Exception:
        logger.exception("db_set_session failed")
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_clear_session(chat_id: int) -> None:
    conn = _db_connect()
    if not conn:
        return
    try:
        with conn.cursor() as cur:
            cur.execute("DELETE FROM user_sessions WHERE chat_id=%s", (chat_id,))
    except Exception:
        logger.exception("db_clear_session failed")
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_weekly_summary(days: int = 7) -> dict:
    conn = _db_connect()
    if not conn:
        return {"ok": False, "error": "DB not configured"}
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT
                  count(*) as total,
                  count(*) FILTER (WHERE error IS NOT NULL) as with_error,
                  avg(rating) as avg_rating
                FROM review_analyses
                WHERE created_at >= now() - (%s || ' days')::interval
                """,
                (days,),
            )
            row = cur.fetchone() or (0, 0, None)
            total = int(row[0])
            with_error = int(row[1])
            avg_rating = float(row[2]) if row[2] is not None else None

            cur.execute(
                """
                SELECT result_json
                FROM review_analyses
                WHERE created_at >= now() - (%s || ' days')::interval
                """,
                (days,),
            )
            rows = cur.fetchall() or []
            sentiments = {"negative": 0, "mixed": 0, "neutral": 0, "positive": 0, "unknown": 0}
            complaints_needed = 0
            aspects_counter: Dict[str, int] = {}
            pain_points_counter: Dict[str, int] = {}
            recommendations_counter: Dict[str, int] = {}

            for (rj,) in rows:
                obj = rj if isinstance(rj, dict) else (json.loads(rj) if rj else {})
                s = (obj.get("sentiment") or {}).get("label") or "unknown"
                if s not in sentiments:
                    s = "unknown"
                sentiments[s] += 1

                comp = (obj.get("complaint") or {})
                if comp.get("needed") is True:
                    complaints_needed += 1

                aspects = obj.get("aspects") or []
                if isinstance(aspects, list):
                    for a in aspects:
                        name = (a or {}).get("name")
                        if name and isinstance(name, str):
                            key = name.strip().lower()
                            aspects_counter[key] = aspects_counter.get(key, 0) + 1

                pains = obj.get("pain_points") or []
                if isinstance(pains, list):
                    for p in pains:
                        item = (p or {}).get("item")
                        if item and isinstance(item, str):
                            key = item.strip().lower()
                            pain_points_counter[key] = pain_points_counter.get(key, 0) + 1

                recs = obj.get("recommendations") or []
                if isinstance(recs, list):
                    for rec in recs:
                        action = (rec or {}).get("action")
                        if action and isinstance(action, str):
                            key = action.strip().lower()
                            recommendations_counter[key] = recommendations_counter.get(key, 0) + 1

            top_aspects = sorted(aspects_counter.items(), key=lambda x: x[1], reverse=True)[:10]
            top_pain_points = sorted(pain_points_counter.items(), key=lambda x: x[1], reverse=True)[:10]
            top_recommendations = sorted(recommendations_counter.items(), key=lambda x: x[1], reverse=True)[:10]

            return {
                "ok": True,
                "days": days,
                "total": total,
                "with_error": with_error,
                "avg_rating": avg_rating,
                "sentiments": sentiments,
                "complaints_needed": complaints_needed,
                "top_aspects": top_aspects,
                "top_pain_points": top_pain_points,
                "top_recommendations": top_recommendations,
            }
    except Exception:
        logger.exception("db_weekly_summary failed")
        return {"ok": False, "error": "db_weekly_summary failed"}
    finally:
        try:
            conn.close()
        except Exception:
            pass

# -----------------------------
# Prompt (FULL + LITE)
# -----------------------------
CX_PROMPT_FULL = r"""
–¢–´ ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å –¥–ª—è Telegram-–±–æ—Ç–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ—Ä–≤–∏—Å–∞ (CX/Service Quality). –ë–æ—Ç –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–ª–æ—â–∞–¥–æ–∫ (—Å–µ–π—á–∞—Å: 2–ì–ò–° –∏ –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã), —Å –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–æ–π –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –ú–æ–¥–µ–ª—å –ò–ò –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî DEEPSEEK, –Ω–æ –ª–æ–≥–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê (—Å—Ç—Ä–æ–≥–æ):
1) –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–ª–æ—â–∞–¥–∫—É (2–ì–ò–° / –Ø–Ω–¥–µ–∫—Å) –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞.
2) –î–∞—Ç—å –ì–õ–£–ë–û–ö–ò–ô –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–∞: –ø—Ä–∏—á–∏–Ω—ã, —Å–±–æ–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–ª–µ–º—ã (–Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Å–µ—Ä–≤–∏—Å–∞), —Ä–∏—Å–∫–∏, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏.
3) –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Ç–∑—ã–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º –ø–ª–æ—â–∞–¥–∫–∏ (–ø–æ —á–µ–∫-–ª–∏—Å—Ç—É –Ω–∏–∂–µ).
4) –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Ç–∑—ã–≤ (—Ä–∞–∑–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ/–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ/—Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ).
5) –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –ø–ª–æ—â–∞–¥–∫–∏ –ò–õ–ò —Ä–µ–π—Ç–∏–Ω–≥ < 2 (—Ç.–µ. 1 –∑–≤–µ–∑–¥–∞) ‚Äî –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∂–∞–ª–æ–±—É –Ω–∞ –æ—Ç–∑—ã–≤:
   - –î–ª—è 2–ì–ò–°: —Ç–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã —Å—Ç—Ä–æ–≥–æ ‚â§ 450 —Å–∏–º–≤–æ–ª–æ–≤ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª—ã).
   - –î–ª—è –Ø–Ω–¥–µ–∫—Å–∞: –∂–∞–ª–æ–±–∞ –∫—Ä–∞—Ç–∫–∞—è, –ø–æ –¥–µ–ª—É.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –ø–µ—Ä–µ–¥–∞–Ω–æ; –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã):
- platform: "2gis" | "yandex" | "unknown" (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- rating: 1..5 (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- review_text: —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
- review_date: –¥–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- business_context: –æ–ø–∏—Å–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞/—É—Å–ª—É–≥/—Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∞ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- branch/city: —Ñ–∏–ª–∏–∞–ª/–≥–æ—Ä–æ–¥ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- meta: –ª—é–±—ã–µ –¥–æ–ø. –ø–æ–ª—è (—è–∑—ã–∫, –∏–º—è –∞–≤—Ç–æ—Ä–∞, —Å—Å—ã–ª–∫–∞, —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ç–≤–µ—Ç –∏ —Ç.–ø.)

–û–ë–©–ò–ï –ü–†–ò–ù–¶–ò–ü–´ –ö–ê–ß–ï–°–¢–í–ê:
- –ù–∏–∫–∞–∫–∏—Ö –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤–æ –≤—Ö–æ–¥–µ.
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Äî —Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≥–∏–ø–æ—Ç–µ–∑—ã + —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
- –¶–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–∞ –¥–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫–∏–º–∏: –¥–æ 12 —Å–ª–æ–≤.
- –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –≤–µ–∂–ª–∏–≤–æ, –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏.
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—É–±–ª–∏–∫—É–π –∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π –ø—É–±–ª–∏—á–Ω–æ ‚Äú–º—ã –ø–æ–¥–∞–¥–∏–º –∂–∞–ª–æ–±—É‚Äù –∏ –Ω–µ —É–≥—Ä–æ–∂–∞–π –∞–≤—Ç–æ—Ä—É.

–®–ê–ì 1. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–õ–û–©–ê–î–ö–ò (–µ—Å–ª–∏ platform –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/unknown)
–í–µ—Ä–Ω–∏:
- platform_detected.value: "2gis" | "yandex" | "unknown"
- confidence 0..1
- signals: 2‚Äì5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
–ï—Å–ª–∏ –Ω–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Äî "unknown" –∏ confidence ‚â§0.4.

–®–ê–ì 2. –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –û–¢–ó–´–í–ê
–°—Ñ–æ—Ä–º–∏—Ä—É–π:
A) review_summary
B) sentiment.label negative/mixed/neutral/positive + score -100..+100
C) emotions 1‚Äì3
D) aspects 3‚Äì8 (name, weight 0..100, evidence)
E) facts_vs_opinions
F) pain_points 1‚Äì5
G) root_cause_hypotheses 1‚Äì3 (process_stage)
H) business_process_flags (—ç—Ç–∞–ø—ã)
I) risks (reputation/ops/finance)
J) recommendations 4‚Äì10 (priority P0/P1/P2, action, expected_effect, effort S/M/L, metric)
K) clarifying_questions 0‚Äì3

–®–ê–ì 3. CHECK-LIST –ù–ê–†–£–®–ï–ù–ò–ô (policy_check)
–í–µ—Ä–Ω–∏:
- has_possible_violations
- possible_violations (category, confidence, evidence)
- notes

2–ì–ò–° —á–µ–∫-–ª–∏—Å—Ç:
1) –Ω–µ –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç/—Å–æ —Å–ª–æ–≤/–¥–∞–≤–Ω–æ >1 –≥–æ–¥–∞
2) —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
3) –¥—É–±–ª–∏–∫–∞—Ç—ã/–∫–æ–ø–∏–ø–∞—Å—Ç (–≥–∏–ø–æ—Ç–µ–∑–∞)
4) –æ—Ç–≤–µ—Ç –Ω–∞ –¥—Ä—É–≥–æ–π –æ—Ç–∑—ã–≤
5) —Ä–µ–∫–ª–∞–º–∞/–Ω–∞–∫—Ä—É—Ç–∫–∞/—Å—Å—ã–ª–∫–∏
6) –∫–∞–ø—Å–ª–æ–∫/—Å–∏–º–≤–æ–ª—ã
7) —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å/—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ
8) –º–∞—Ç/–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è/—É–≥—Ä–æ–∑—ã/–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è
9) –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ–∫—É–º–µ–Ω—Ç—ã/–º–µ–¥.

–Ø–Ω–¥–µ–∫—Å —á–µ–∫-–ª–∏—Å—Ç:
1) –Ω–µ –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç
2) –Ω–µ–≤–µ—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç/–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
3) –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ–∫—É–º–µ–Ω—Ç—ã/–º–µ–¥
4) —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –±–µ–∑ —Å–æ–≥–ª–∞—Å–∏—è (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è)
5) –æ—Ç–∑—ã–≤ –∫–∞–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞
6) —Ä–µ–∫–ª–∞–º–∞/—Å–ø–∞–º/—Å—Å—ã–ª–∫–∏/–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
7) –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–π/–Ω–∞–∫—Ä—É—á–µ–Ω–Ω—ã–π (–≥–∏–ø–æ—Ç–µ–∑–∞)
8) —É–≥—Ä–æ–∑—ã/–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è/18+

–®–ê–ì 4. public_reply
2‚Äì8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –±–µ–∑ –ü–î–Ω, –±–µ–∑ —É–≥—Ä–æ–∑.

–®–ê–ì 5. complaint
complaint.needed=true –µ—Å–ª–∏:
a) rating < 2 (–µ—Å–ª–∏ rating –µ—Å—Ç—å)
–∏–ª–∏ b) violations —Å confidence >=0.6
–∏–ª–∏ c) —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª ‚Äú–Ω–µ –±—ã–ª–æ –≤–∏–∑–∏—Ç–∞‚Äù (–≥–∏–ø–æ—Ç–µ–∑–∞)
–î–ª—è 2–ì–ò–°: complaint.text <= 450 —Å–∏–º–≤–æ–ª–æ–≤ + –≤–µ—Ä–Ω–∏ char_count.

–í–´–•–û–î–ù–û–ô –§–û–†–ú–ê–¢ (–°–¢–†–û–ì–û: –≤–µ—Ä–Ω—É—Ç—å –¢–û–õ–¨–ö–û JSON)
{
  "platform_detected": {"value":"2gis|yandex|unknown","confidence":0.0,"signals":["..."]},
  "review_summary":"...",
  "sentiment":{"label":"negative|mixed|neutral|positive","score":0},
  "emotions":[{"name":"...","intensity":0}],
  "aspects":[{"name":"...","weight":0,"evidence":["..."]}],
  "facts_vs_opinions":{"facts":["..."],"opinions":["..."]},
  "pain_points":[{"item":"...","severity":"low|medium|high","evidence":["..."]}],
  "root_cause_hypotheses":[{"hypothesis":"...","confidence":0.0,"evidence":["..."],"process_stage":"..."}],
  "business_process_flags":[{"stage":"...","issue":"...","why_it_matters":"..."}],
  "risks":[{"type":"reputation|ops|finance","level":"low|medium|high","why":"..."}],
  "recommendations":[{"priority":"P0|P1|P2","action":"...","expected_effect":"...","effort":"S|M|L","metric":"..."}],
  "clarifying_questions":["..."],
  "policy_check":{
    "has_possible_violations":false,
    "possible_violations":[{"category":"...","confidence":0.0,"evidence":["..."]}],
    "notes":"..."
  },
  "public_reply":{"tone":"...","text":"..."},
  "complaint":{"needed":false,"reasons":["..."],"text":"...","char_count":0}
}
"""

CX_PROMPT_LITE = r"""
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –ø–æ —Å—Ö–µ–º–µ:
platform_detected, review_summary, sentiment, emotions, aspects, facts_vs_opinions, pain_points,
root_cause_hypotheses, business_process_flags, risks, recommendations, clarifying_questions,
policy_check, public_reply, complaint.
–ù–∏–∫–∞–∫–∏—Ö markdown, –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Äî –≥–∏–ø–æ—Ç–µ–∑—ã + confidence.
"""

def get_cx_prompt() -> str:
    return CX_PROMPT_LITE if CX_PROMPT_MODE == "lite" else CX_PROMPT_FULL

# -----------------------------
# Settings / Sessions
# -----------------------------
SESSION_TTL_MINUTES = 15

def _current_engine() -> str:
    override = db_get_setting("ai_engine_override") or {}
    val = (override.get("value") or "").strip().lower()
    if val:
        return val
    return (os.getenv("AI_ENGINE") or AI_ENGINE).strip().lower()

def _business_context() -> Optional[str]:
    ctx = db_get_setting("business_context") or {}
    val = (ctx.get("value") or "").strip()
    return val or None

def _get_active_session(chat_id: int) -> Optional[dict]:
    sess = db_get_session(chat_id)
    if not sess:
        return None
    updated_at = sess.get("updated_at")
    if isinstance(updated_at, datetime):
        current = datetime.now(updated_at.tzinfo or timezone.utc)
        if updated_at < current - timedelta(minutes=SESSION_TTL_MINUTES):
            db_clear_session(chat_id)
            return None
    return sess

def _hash_review(text: str) -> str:
    return hashlib.sha256(text.strip().encode("utf-8")).hexdigest()

# -----------------------------
# AI clients
# -----------------------------
def ai_chat(messages: List[Dict[str, str]]) -> str:
    engine = _current_engine()

    if engine in ("deepseek", "deep-seek", "ds"):
        return call_deepseek(messages)

    if engine in ("openai", "gpt"):
        return call_openai(messages)

    if engine in ("gemini", "google"):
        return call_gemini(messages)

    if engine in ("grok", "xai"):
        return call_grok(messages)

    raise RuntimeError(f"Unknown AI_ENGINE: {engine}")

def call_deepseek(messages: List[Dict[str, str]]) -> str:
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("DEEPSEEK_API_KEY not set")

    # 1) Prefer OpenAI SDK if available
    if OPENAI_SDK_AVAILABLE and OpenAI is not None:
        try:
            client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
            resp = client.chat.completions.create(
                model=DEEPSEEK_MODEL,
                messages=messages,
                temperature=0.2,
                timeout=AI_TIMEOUT,
            )
            text = (resp.choices[0].message.content or "").strip()
            return text
        except Exception as e:
            logger.warning("DeepSeek via OpenAI SDK failed. err=%s", str(e)[:200])
            if not DEEPSEEK_ALLOW_REQUESTS_FALLBACK:
                raise RuntimeError("DeepSeek gateway blocked or SDK failed (requests fallback disabled).")

    if not DEEPSEEK_ALLOW_REQUESTS_FALLBACK:
        raise RuntimeError("DeepSeek requests fallback disabled (set DEEPSEEK_ALLOW_REQUESTS_FALLBACK=1 to enable).")

    # 2) Fallback: requests (can be blocked by Cloudflare)
    payload = {
        "model": DEEPSEEK_MODEL,
        "messages": messages,
        "temperature": 0.2,
        "stream": False,
    }
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0 (compatible; telegramreviewsbot/1.0; Railway)",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
        "Connection": "keep-alive",
    }

    resp = requests.post(DEEPSEEK_URL, json=payload, headers=headers, timeout=AI_TIMEOUT)
    body_preview = _redact(resp.text[:900])
    logger.info("DeepSeek status=%s body=%s", resp.status_code, body_preview)

    if "<html" in resp.text.lower() or "just a moment" in resp.text.lower():
        logger.error("DeepSeek gateway returned HTML (cloudflare_block=true) status=%s", resp.status_code)
        raise RuntimeError(f"DeepSeek gateway returned HTML (likely Cloudflare). status={resp.status_code}")

    resp.raise_for_status()
    data = resp.json()
    if "error" in data:
        err_obj = data.get("error") or {}
        err_msg = err_obj.get("message") or err_obj.get("error") or str(err_obj)
        raise RuntimeError(f"DeepSeek API error: {err_msg}")

    choices = data.get("choices") or []
    if not choices:
        raise RuntimeError("DeepSeek API returned no choices")
    msg = choices[0].get("message") or {}
    return (msg.get("content") or "").strip()

def call_openai(messages: List[Dict[str, str]]) -> str:
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY not set")

    if OPENAI_SDK_AVAILABLE and OpenAI is not None:
        client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.2,
            timeout=AI_TIMEOUT,
        )
        return (resp.choices[0].message.content or "").strip()

    url = f"{OPENAI_BASE_URL}/chat/completions"
    payload = {"model": OPENAI_MODEL, "messages": messages, "temperature": 0.2}
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    resp = requests.post(url, json=payload, headers=headers, timeout=AI_TIMEOUT)
    logger.info("OpenAI status=%s body=%s", resp.status_code, _redact(resp.text[:700]))
    resp.raise_for_status()
    data = resp.json()
    return (data["choices"][0]["message"]["content"] or "").strip()

def call_gemini(messages: List[Dict[str, str]]) -> str:
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY not set")

    joined = "\n".join([f"{m.get('role','user')}: {m.get('content','')}" for m in messages])
    payload = {"contents": [{"role": "user", "parts": [{"text": joined}]}]}
    headers = {"Content-Type": "application/json", "X-goog-api-key": GEMINI_API_KEY}
    resp = requests.post(GEMINI_URL, json=payload, headers=headers, timeout=AI_TIMEOUT)
    logger.info("Gemini status=%s body=%s", resp.status_code, _redact(resp.text[:700]))
    resp.raise_for_status()
    data = resp.json()

    candidates = data.get("candidates") or []
    if not candidates:
        return ""
    parts = (candidates[0].get("content") or {}).get("parts") or []
    if not parts:
        return ""
    return (parts[0].get("text") or "").strip()

def call_grok(messages: List[Dict[str, str]]) -> str:
    raise RuntimeError("GROK engine not configured yet (set GROK_BASE_URL/GROK_API_KEY)")

# -----------------------------
# JSON extraction from LLM response
# -----------------------------
def extract_first_json(text: str) -> Tuple[Optional[dict], Optional[str]]:
    if not text:
        return None, "empty_ai_response"

    cleaned = text.strip()
    cleaned = re.sub(r"^```(?:json)?\s*", "", cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r"\s*```$", "", cleaned)

    try:
        obj = json.loads(cleaned)
        if isinstance(obj, dict):
            return obj, None
        return None, "json_is_not_object"
    except Exception:
        pass

    start = cleaned.find("{")
    end = cleaned.rfind("}")
    if start != -1 and end != -1 and end > start:
        candidate = cleaned[start:end + 1]
        try:
            obj = json.loads(candidate)
            if isinstance(obj, dict):
                return obj, None
            return None, "json_is_not_object"
        except Exception as e:
            return None, f"json_parse_failed: {str(e)[:120]}"

    return None, "no_json_object_found"

# -----------------------------
# CX analyze
# -----------------------------
def cx_analyze(input_obj: dict) -> Tuple[Optional[dict], str]:
    system_prompt = get_cx_prompt()
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": json.dumps(input_obj, ensure_ascii=False)},
    ]
    raw = ai_chat(messages)
    parsed, err = extract_first_json(raw)
    if parsed is None:
        raise RuntimeError(f"AI returned invalid JSON. err={err}")
    return parsed, raw

# -----------------------------
# Inline keyboard
# -----------------------------
def analysis_keyboard(analysis_id: int, include_reanalyze: bool = False, review_id: Optional[int] = None) -> dict:
    rows = [
        [
            {"text": "‚úçÔ∏è –û—Ç–≤–µ—Ç", "callback_data": f"reply:{analysis_id}"},
            {"text": "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞", "callback_data": f"complaint:{analysis_id}"},
        ],
        [
            {"text": "üìå –û—Ç–≤–µ—Ç + –∂–∞–ª–æ–±–∞", "callback_data": f"both:{analysis_id}"},
            {"text": "üßæ JSON", "callback_data": f"json:{analysis_id}"},
        ],
    ]
    if include_reanalyze and review_id is not None:
        rows.append([{"text": "üîÑ –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å", "callback_data": f"reanalyze_review:{review_id}"}])
    return {"inline_keyboard": rows}

# -----------------------------
# Commands
# -----------------------------
HELP_TEXT = (
    "–ö–æ–º–∞–Ω–¥—ã:\n"
    "/start ‚Äî –º–µ–Ω—é\n"
    "/help ‚Äî –ø–æ–º–æ—â—å\n"
    "/myid ‚Äî –≤–∞—à ID\n"
    "/engine ‚Äî —Ç–µ–∫—É—â–∏–π AI_ENGINE\n"
    "/setengine ‚Äî –≤—ã–±—Ä–∞—Ç—å –¥–≤–∏–∂–æ–∫ (–∫–Ω–æ–ø–∫–∏)\n"
    "/setcontext ‚Äî –∑–∞–¥–∞—Ç—å –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–µ–∫—Å—Ç)\n"
    "/addreview ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ (–ø–æ—à–∞–≥–æ–≤–æ)\n"
    "/review <id> ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Ç–∑—ã–≤\n"
    "/analyze <—Ç–µ–∫—Å—Ç> ‚Äî –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)\n"
    "/analyzereview <id> ‚Äî –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞\n"
    "/find ‚Äî –ø–æ–∏—Å–∫ –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ—à–∞–≥–æ–≤–æ)\n"
    "/weeklyreport ‚Äî –Ω–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç\n"
    "/exportcsv ‚Äî —ç–∫—Å–ø–æ—Ä—Ç CSV\n"
    "/diag ‚Äî —Å–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞\n"
    "/cancel ‚Äî —Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è\n"
)

INSTRUCTION_TEXT = (
    "**–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è (–æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ):**\n\n"
    "1. –ù–∞–∂–º–∏ **‚ûï –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤**\n"
    "2. –í—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ (–∫–∞–∫ –µ—Å—Ç—å) –∏ –æ—Ç–ø—Ä–∞–≤—å\n"
    "3. –í—ã–±–µ—Ä–∏ –ø–ª–æ—â–∞–¥–∫—É (**–Ø–Ω–¥–µ–∫—Å** –∏–ª–∏ **2–ì–ò–°**)\n"
    "4. –í—ã–±–µ—Ä–∏ —Ä–µ–π—Ç–∏–Ω–≥ (‚≠ê1‚Äì‚≠ê5)\n"
    "5. –ë–æ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç –æ—Ç–∑—ã–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç **üß† –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å**\n"
    "6. –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—è–≤—è—Ç—Å—è –∫–Ω–æ–ø–∫–∏:\n"
    "   **‚úçÔ∏è –û—Ç–≤–µ—Ç** ‚Äî –≥–æ—Ç–æ–≤—ã–π –ø—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É\n"
    "   **‚ö†Ô∏è –ñ–∞–ª–æ–±–∞** ‚Äî —Ç–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã (–µ—Å–ª–∏ –æ—Ç–∑—ã–≤ –Ω–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–ª–∏ ‚≠ê1)\n"
    "   **üßæ JSON** ‚Äî –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ (–¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏/–æ—Ç—á—ë—Ç–æ–≤)\n\n"
    "**–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:** –Ω–∞–∂–º–∏ **üõ† –°–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞** –∏ –ø—Ä–∏—à–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É."
)

def main_menu_keyboard() -> dict:
    return {
        "keyboard": [
            ["üìò –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "üìã –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥", "üÜî –ú–æ–π ID"],
            ["üõ† –°–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "‚ûï –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤", "üß† –ê–Ω–∞–ª–∏–∑ –ø–æ ID"],
            ["üîç –ü–æ–∏—Å–∫ –æ—Ç–∑—ã–≤–æ–≤", "üìä –ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç", "üì§ –≠–∫—Å–ø–æ—Ä—Ç CSV"],
            ["‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"],
        ],
        "resize_keyboard": True,
    }

def settings_keyboard() -> dict:
    return {
        "inline_keyboard": [
            [{"text": "–í—ã–±–æ—Ä –ò–ò", "callback_data": "settings:engine"}],
            [{"text": "–ë–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç", "callback_data": "settings:context"}],
        ]
    }

STATE_NONE = "NONE"
STATE_WAIT_REVIEW_TEXT = "WAIT_REVIEW_TEXT"
STATE_WAIT_PLATFORM = "WAIT_PLATFORM"
STATE_WAIT_RATING = "WAIT_RATING"
STATE_WAIT_DUP_CONFIRM = "WAIT_DUP_CONFIRM"
STATE_WAIT_ANALYZE_ID = "WAIT_ANALYZE_ID"
STATE_WAIT_CONTEXT = "WAIT_CONTEXT"
STATE_FIND_PLATFORM = "FIND_PLATFORM"
STATE_FIND_RATING = "FIND_RATING"
STATE_FIND_DAYS = "FIND_DAYS"

def _reset_state(chat_id: int) -> None:
    db_clear_session(chat_id)

def parse_kv_args(text: str) -> Tuple[Dict[str, str], str]:
    parts = text.strip().split()
    kv: Dict[str, str] = {}
    rest_start = 0
    for i, p in enumerate(parts):
        if "=" in p and not p.startswith("http"):
            k, v = p.split("=", 1)
            if k and v:
                kv[k.strip().lower()] = v.strip()
                rest_start = i + 1
                continue
        break
    rest = " ".join(parts[rest_start:])
    return kv, rest

# -----------------------------
# Background analysis
# -----------------------------
def background_analyze(chat_id: int, user_id: int, review_text: str, platform_hint: str = "unknown",
                      rating: Optional[int] = None, review_id: Optional[int] = None) -> None:
    engine = _current_engine()
    model_name = ""
    if engine == "deepseek":
        model_name = DEEPSEEK_MODEL
    elif engine == "openai":
        model_name = OPENAI_MODEL
    elif engine == "gemini":
        model_name = GEMINI_MODEL
    elif engine == "grok":
        model_name = GROK_MODEL

    input_obj = {
        "platform": platform_hint,
        "rating": rating,
        "review_text": review_text,
        "review_date": None,
        "business_context": _business_context(),
        "branch/city": None,
        "meta": {},
    }

    try:
        parsed, _raw = cx_analyze(input_obj)

        analysis_id = db_insert_analysis(
            review_id=review_id,
            platform=parsed.get("platform_detected", {}).get("value") if isinstance(parsed.get("platform_detected"), dict) else platform_hint,
            rating=rating,
            review_text=review_text,
            result_json=parsed,
            error=None,
            model=model_name,
            engine=engine,
            created_by=user_id,
        ) or 0

        brief = format_analysis_brief(parsed)
        send_message(
            chat_id,
            f"‚úÖ –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤. ID: {analysis_id}\n\n{brief}",
            reply_markup=analysis_keyboard(analysis_id, include_reanalyze=bool(review_id), review_id=review_id),
        )

    except Exception as e:
        err_text = str(e)
        logger.error("AI exception: %s", err_text)
        logger.exception("AI exception traceback")

        fallback_json = {"_error": "AI failed or returned invalid JSON (see logs)", "engine": engine}
        analysis_id = db_insert_analysis(
            review_id=review_id,
            platform=platform_hint,
            rating=rating,
            review_text=review_text,
            result_json=fallback_json,
            error=err_text[:800],
            model=model_name,
            engine=engine,
            created_by=user_id,
        ) or 0

        error_type = "unknown"
        if "Cloudflare" in err_text or "returned HTML" in err_text or "just a moment" in err_text.lower():
            error_type = "cloudflare_block"
        elif "status=403" in err_text:
            error_type = "http_403"
        elif "status=429" in err_text:
            error_type = "http_429"
        elif "json" in err_text.lower():
            error_type = "parse_error"

        if error_type == "cloudflare_block":
            msg = "‚ùå –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —à–ª—é–∑–∞ (Cloudflare). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏ –¥–≤–∏–∂–æ–∫."
        else:
            msg = "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç –ò–ò. –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å –æ—à–∏–±–∫–æ–π. ID: %d\n–ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏ CX_PROMPT_MODE=lite." % analysis_id

        send_message(
            chat_id,
            msg,
            reply_markup=analysis_keyboard(analysis_id, include_reanalyze=bool(review_id), review_id=review_id),
        )
        notify_admins(
            "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ò–ò –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ #%s\nengine=%s model=%s\n—Ç–∏–ø=%s\n–æ—Ç–∫—Ä–æ–π —Å–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É: /diag"
            % (review_id or analysis_id, engine, model_name or "-", error_type)
        )

# -----------------------------
# HTTP routes
# -----------------------------
@app.get("/")
def health():
    set_webhook_once()
    return jsonify({
        "ok": True,
        "status": "running",
        "webhook_path": WEBHOOK_PATH,
        "ai_engine": _current_engine(),
        "prompt_mode": (os.getenv("CX_PROMPT_MODE") or CX_PROMPT_MODE).strip().lower(),
        "admin_mode": ADMIN_MODE,
        "db": "postgres" if DB_OK else "disabled",
        "deepseek_url": DEEPSEEK_URL,
        "openai_sdk": OPENAI_SDK_AVAILABLE,
    })

@app.get("/diag/ai")
def diag_ai():
    if DIAG_TOKEN:
        token = request.args.get("token", "").strip()
        if token != DIAG_TOKEN:
            return jsonify({"ok": False, "error": "forbidden"}), 403

    engine = _current_engine()
    prompt_mode = (os.getenv("CX_PROMPT_MODE") or CX_PROMPT_MODE).strip().lower()

    messages = [
        {"role": "system", "content": "Reply with exactly: OK"},
        {"role": "user", "content": "ping"},
    ]
    try:
        raw = ai_chat(messages)
        return jsonify({
            "ok": True,
            "engine": engine,
            "prompt_mode": prompt_mode,
            "deepseek_url": DEEPSEEK_URL if engine == "deepseek" else None,
            "raw_preview": raw[:300],
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "engine": engine,
            "prompt_mode": prompt_mode,
            "deepseek_url": DEEPSEEK_URL if engine == "deepseek" else None,
            "error": str(e)[:700],
        }), 500

@app.get("/cron/weekly")
def cron_weekly():
    if not CRON_TOKEN:
        return jsonify({"ok": False, "error": "CRON_TOKEN not set"}), 400

    token = request.args.get("token", "").strip()
    if token != CRON_TOKEN:
        return jsonify({"ok": False, "error": "forbidden"}), 403

    days = int(request.args.get("days", "7"))
    summary = db_weekly_summary(days=days)
    if not summary.get("ok"):
        return jsonify(summary), 500

    sent_to = []
    text = format_weekly_report(summary)
    for cid in ADMIN_CHAT_IDS:
        send_message(cid, text)
        sent_to.append(cid)

    return jsonify({"ok": True, "days": days, "sent_to": sent_to})

@app.post(WEBHOOK_PATH)
def telegram_webhook():
    update = request.get_json(silent=True) or {}
    logger.info("Update: %s", _redact(json.dumps(update, ensure_ascii=False)[:1200]))

    # callback
    if "callback_query" in update:
        cq = update["callback_query"]
        cq_id = cq.get("id", "")
        msg = cq.get("message") or {}
        chat = msg.get("chat") or {}
        chat_id = chat.get("id")
        user = cq.get("from") or {}
        user_id = user.get("id")
        data = (cq.get("data") or "").strip()

        if not _is_admin(user_id, chat_id):
            if chat_id:
                send_message(chat_id, "‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
            if cq_id:
                answer_callback_query(cq_id, "–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω", show_alert=True)
            return "ok"

        try:
            handle_callback(chat_id, cq_id, data)
        except Exception:
            logger.exception("handle_callback failed")
            if cq_id:
                answer_callback_query(cq_id, "–û—à–∏–±–∫–∞", show_alert=True)
        return "ok"

    message = update.get("message") or {}
    chat = message.get("chat") or {}
    chat_id = chat.get("id")
    user = message.get("from") or {}
    user_id = user.get("id")
    text = (message.get("text") or "").strip()

    logger.info("Parsed: chat_id=%s user_id=%s text=%r", chat_id, user_id, text[:220])

    if not chat_id or not user_id:
        return "ok"

    if not _is_admin(user_id, chat_id):
        send_message(chat_id, "‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return "ok"

    # button shortcuts
    if text == "üìò –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è":
        send_message(chat_id, INSTRUCTION_TEXT, parse_mode="Markdown")
        return "ok"
    if text == "üìã –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥":
        send_message(chat_id, HELP_TEXT)
        return "ok"
    if text == "üÜî –ú–æ–π ID":
        send_message(chat_id, f"–í–∞—à ID: {chat_id}")
        return "ok"
    if text == "üõ† –°–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞":
        send_message(chat_id, diag_text())
        try:
            raw = ai_chat(
                [
                    {"role": "system", "content": "Reply with exactly: OK"},
                    {"role": "user", "content": "ping"},
                ]
            )
            send_message(chat_id, f"AI test: OK\npreview: {raw[:120]}")
        except Exception as e:
            send_message(chat_id, f"AI test: FAIL\nerror: {str(e)[:400]}")
        return "ok"
    if text == "‚ûï –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤":
        start_add_review(chat_id)
        return "ok"
    if text == "üß† –ê–Ω–∞–ª–∏–∑ –ø–æ ID":
        _reset_state(chat_id)
        db_set_session(chat_id, STATE_WAIT_ANALYZE_ID, {})
        send_message(chat_id, "–û—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä –æ—Ç–∑—ã–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä 12).\n(–û—Ç–º–µ–Ω–∞: /cancel)")
        return "ok"
    if text == "üîç –ü–æ–∏—Å–∫ –æ—Ç–∑—ã–≤–æ–≤":
        start_find_flow(chat_id)
        return "ok"
    if text == "üìä –ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç":
        summary = db_weekly_summary(days=7)
        if not summary.get("ok"):
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç—á—ë—Ç (DB?).")
            return "ok"
        send_message(chat_id, format_weekly_report(summary))
        return "ok"
    if text == "üì§ –≠–∫—Å–ø–æ—Ä—Ç CSV":
        rows = db_export_reviews(days=30, limit=500)
        if not rows:
            send_message(chat_id, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.")
            return "ok"
        content = build_csv_export(rows)
        send_document(chat_id, "reviews_export.csv", content)
        return "ok"
    if text == "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏":
        send_message(chat_id, "–ù–∞—Å—Ç—Ä–æ–π–∫–∏:", reply_markup=settings_keyboard())
        return "ok"

    # commands
    if text.startswith("/start"):
        name = _display_name(user)
        send_message(
            chat_id,
            f"–ü—Ä–∏–≤–µ—Ç, {name}!\n"
            "–Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º –∏ –æ—Ç–∑—ã–≤–∞–º–∏ –Ω–∞ **–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç–∞—Ö** –∏ **2–ì–ò–°**: "
            "—Ö—Ä–∞–Ω—é –æ—Ç–∑—ã–≤—ã, –¥–µ–ª–∞—é –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑, –ø–æ–º–æ–≥–∞—é –≥–æ—Ç–æ–≤–∏—Ç—å –ø—É–±–ª–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏ –∂–∞–ª–æ–±—ã, "
            "—Ñ–æ—Ä–º–∏—Ä—É—é –æ—Ç—á—ë—Ç—ã ‚Äî —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏ —É–ª—É—á—à–∞—Ç—å —Ä–µ–π—Ç–∏–Ω–≥.",
            reply_markup=main_menu_keyboard(),
            parse_mode="Markdown",
        )
        return "ok"

    if text.startswith("/help"):
        send_message(chat_id, HELP_TEXT)
        return "ok"

    if text.startswith("/myid"):
        send_message(chat_id, f"–í–∞—à ID: {chat_id}")
        return "ok"

    if text.startswith("/engine"):
        send_message(chat_id, f"–¢–µ–∫—É—â–∏–π AI_ENGINE: {_current_engine()}")
        return "ok"

    if text.startswith("/setengine"):
        send_message(chat_id, "–í—ã–±–µ—Ä–∏ –¥–≤–∏–∂–æ–∫:", reply_markup={"inline_keyboard": [[
            {"text": "DeepSeek (Artemox)", "callback_data": "set_engine:deepseek"},
            {"text": "OpenAI", "callback_data": "set_engine:openai"},
        ], [
            {"text": "Gemini", "callback_data": "set_engine:gemini"},
            {"text": "Grok", "callback_data": "set_engine:grok"},
        ]]})
        return "ok"

    if text.startswith("/setcontext"):
        _reset_state(chat_id)
        db_set_session(chat_id, STATE_WAIT_CONTEXT, {})
        send_message(chat_id, "–û—Ç–ø—Ä–∞–≤—å –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")
        return "ok"

    if text.startswith("/addreview"):
        start_add_review(chat_id)
        return "ok"

    if text.startswith("/find"):
        start_find_flow(chat_id)
        return "ok"

    if text.startswith("/diag"):
        send_message(chat_id, diag_text())
        try:
            raw = ai_chat(
                [
                    {"role": "system", "content": "Reply with exactly: OK"},
                    {"role": "user", "content": "ping"},
                ]
            )
            send_message(chat_id, f"AI test: OK\npreview: {raw[:120]}")
        except Exception as e:
            send_message(chat_id, f"AI test: FAIL\nerror: {str(e)[:400]}")
        return "ok"

    if text.startswith("/exportcsv"):
        rows = db_export_reviews(days=30, limit=500)
        if not rows:
            send_message(chat_id, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.")
            return "ok"
        content = build_csv_export(rows)
        send_document(chat_id, "reviews_export.csv", content)
        return "ok"

    if text.startswith("/cancel"):
        _reset_state(chat_id)
        send_message(chat_id, "–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–±—Ä–æ—à–µ–Ω–æ.")
        return "ok"

    if text.startswith("/review"):
        parts = text.split()
        if len(parts) < 2 or not parts[1].isdigit():
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /review <id>")
            return "ok"
        rid = int(parts[1])
        r = db_get_review(rid)
        if not r:
            send_message(chat_id, "‚ùå –û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return "ok"
        send_message(chat_id, f"#{r['id']} [{r.get('platform') or r['source']}] ‚≠ê{r['rating'] or '-'}\n\n{r['review_text']}")
        return "ok"

    if text.startswith("/analyzereview"):
        parts = text.split()
        if len(parts) < 2 or not parts[1].isdigit():
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /analyzereview <id>")
            return "ok"
        rid = int(parts[1])
        r = db_get_review(rid)
        if not r:
            send_message(chat_id, "‚ùå –û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return "ok"
        existing = db_get_analysis_by_review_id(rid)
        if existing and not existing.get("error"):
            brief = format_analysis_brief(existing.get("result_json") or {})
            send_message(
                chat_id,
                f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}:\n\n{brief}",
                reply_markup=analysis_keyboard(existing["id"], include_reanalyze=True, review_id=rid),
            )
            return "ok"
        send_message(chat_id, f"–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}‚Ä¶")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, user_id, r["review_text"], r.get("platform") or "unknown", r.get("rating"), rid),
            daemon=True,
        ).start()
        return "ok"

    if text.startswith("/weeklyreport"):
        args = text[len("/weeklyreport"):].strip()
        kv, _ = parse_kv_args(args) if args else ({}, "")
        days = int(kv.get("days", "7"))
        summary = db_weekly_summary(days=days)
        if not summary.get("ok"):
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç—á—ë—Ç (DB?).")
            return "ok"
        send_message(chat_id, format_weekly_report(summary))
        return "ok"

    if text.startswith("/analyze"):
        analyze_text = text[len("/analyze"):].strip()
        if not analyze_text:
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /analyze <—Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞>")
            return "ok"
        send_message(chat_id, "–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑...")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, user_id, analyze_text, "unknown", None, None),
            daemon=True,
        ).start()
        return "ok"

    # state handling
    session = _get_active_session(chat_id)
    if session:
        state = session.get("state")
        payload = session.get("payload") or {}

        if state == STATE_WAIT_REVIEW_TEXT:
            review_text = text.strip()
            if not review_text:
                send_message(chat_id, "–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π. –í—Å—Ç–∞–≤—å –æ—Ç–∑—ã–≤ –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")
                return "ok"
            payload["review_text"] = review_text
            payload["added_by"] = user_id
            db_set_session(chat_id, STATE_WAIT_PLATFORM, payload)
            send_message(
                chat_id,
                "–í—ã–±–µ—Ä–∏ –ø–ª–æ—â–∞–¥–∫—É:",
                reply_markup={
                    "inline_keyboard": [
                        [{"text": "üü° –Ø–Ω–¥–µ–∫—Å", "callback_data": "platform:yandex"}],
                        [{"text": "üü¢ 2–ì–ò–°", "callback_data": "platform:2gis"}],
                    ]
                },
            )
            return "ok"

        if state == STATE_WAIT_ANALYZE_ID:
            if not text.isdigit():
                send_message(chat_id, "–ù—É–∂–µ–Ω –Ω–æ–º–µ—Ä –æ—Ç–∑—ã–≤–∞ (—á–∏—Å–ª–æ).")
                return "ok"
            rid = int(text)
            r = db_get_review(rid)
            if not r:
                send_message(chat_id, "‚ùå –û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                return "ok"
            existing = db_get_analysis_by_review_id(rid)
            if existing and not existing.get("error"):
                brief = format_analysis_brief(existing.get("result_json") or {})
                send_message(
                    chat_id,
                    f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}:\n\n{brief}",
                    reply_markup=analysis_keyboard(existing["id"], include_reanalyze=True, review_id=rid),
                )
                _reset_state(chat_id)
                return "ok"
            send_message(chat_id, f"–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}‚Ä¶")
            threading.Thread(
                target=background_analyze,
                args=(chat_id, user_id, r["review_text"], r.get("platform") or "unknown", r.get("rating"), rid),
                daemon=True,
            ).start()
            _reset_state(chat_id)
            return "ok"

        if state == STATE_WAIT_CONTEXT:
            ctx_text = text.strip()
            if not ctx_text:
                send_message(chat_id, "–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π. –û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç –µ—â—ë —Ä–∞–∑.")
                return "ok"
            db_set_setting("business_context", {"value": ctx_text})
            _reset_state(chat_id)
            send_message(chat_id, "‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
            return "ok"

    return "ok"

# -----------------------------
# Callback handler
# -----------------------------
def handle_callback(chat_id: Optional[int], callback_query_id: str, data: str) -> None:
    if not chat_id:
        answer_callback_query(callback_query_id, "–ù–µ—Ç chat_id", show_alert=True)
        return

    if data == "cancel":
        _reset_state(chat_id)
        answer_callback_query(callback_query_id, "–û—Ç–º–µ–Ω–µ–Ω–æ")
        return

    if data.startswith("platform:"):
        platform = data.split(":", 1)[1]
        session = _get_active_session(chat_id)
        if not session or session.get("state") != STATE_WAIT_PLATFORM:
            answer_callback_query(callback_query_id, "–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
            return
        payload = session.get("payload") or {}
        payload["platform"] = platform
        db_set_session(chat_id, STATE_WAIT_RATING, payload)
        answer_callback_query(callback_query_id, "–û–∫")
        send_message(
            chat_id,
            "–£–∫–∞–∂–∏ —Ä–µ–π—Ç–∏–Ω–≥:",
            reply_markup={
                "inline_keyboard": [[
                    {"text": "‚≠ê1", "callback_data": "rating:1"},
                    {"text": "‚≠ê2", "callback_data": "rating:2"},
                    {"text": "‚≠ê3", "callback_data": "rating:3"},
                    {"text": "‚≠ê4", "callback_data": "rating:4"},
                    {"text": "‚≠ê5", "callback_data": "rating:5"},
                ]]
            },
        )
        return

    if data.startswith("rating:"):
        rating_str = data.split(":", 1)[1]
        if not rating_str.isdigit():
            answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥", show_alert=True)
            return
        rating = int(rating_str)
        session = _get_active_session(chat_id)
        if not session or session.get("state") != STATE_WAIT_RATING:
            answer_callback_query(callback_query_id, "–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
            return
        payload = session.get("payload") or {}
        review_text = payload.get("review_text") or ""
        platform = payload.get("platform") or "unknown"
        added_by = payload.get("added_by")
        review_hash = _hash_review(review_text)

        duplicate = db_find_duplicate_review(review_hash)
        if duplicate:
            db_set_session(chat_id, STATE_WAIT_DUP_CONFIRM, {
                "review_text": review_text,
                "platform": platform,
                "rating": rating,
                "review_hash": review_hash,
                "added_by": added_by,
            })
            answer_callback_query(callback_query_id, "–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            send_message(
                chat_id,
                f"‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —Ç–∞–∫–æ–π –æ—Ç–∑—ã–≤ —É–∂–µ –¥–æ–±–∞–≤–ª—è–ª–∏ (#{duplicate['id']}, {duplicate['created_at']}). –í—Å—ë —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å?",
                reply_markup={
                    "inline_keyboard": [
                        [{"text": "‚úÖ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", "callback_data": "dup_save:1"}],
                        [{"text": "‚ùå –û—Ç–º–µ–Ω–∞", "callback_data": "cancel"}],
                    ]
                },
            )
            return

        rid = db_insert_review(
            source="manual",
            rating=rating,
            review_text=review_text,
            meta={"added_by": added_by} if added_by else {},
            platform=platform,
            review_hash=review_hash,
        )
        _reset_state(chat_id)
        answer_callback_query(callback_query_id, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        if not rid:
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤ (DB?).")
            return
        send_message(
            chat_id,
            f"‚úÖ –û—Ç–∑—ã–≤ –¥–æ–±–∞–≤–ª–µ–Ω. –ù–æ–º–µ—Ä: #{rid}\n–•–æ—á–µ—à—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –ò–ò-–∞–Ω–∞–ª–∏–∑?",
            reply_markup={
                "inline_keyboard": [
                    [{"text": "üß† –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", "callback_data": f"analyze_review:{rid}"}],
                    [{"text": "‚ùå –ù–µ—Ç", "callback_data": "cancel"}],
                ]
            },
        )
        return

    if data.startswith("dup_save:"):
        session = _get_active_session(chat_id)
        if not session or session.get("state") != STATE_WAIT_DUP_CONFIRM:
            answer_callback_query(callback_query_id, "–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
            return
        payload = session.get("payload") or {}
        review_text = payload.get("review_text") or ""
        platform = payload.get("platform") or "unknown"
        rating = payload.get("rating")
        review_hash = payload.get("review_hash")
        added_by = payload.get("added_by")

        rid = db_insert_review(
            source="manual",
            rating=rating,
            review_text=review_text,
            meta={"added_by": added_by} if added_by else {},
            platform=platform,
            review_hash=review_hash,
        )
        _reset_state(chat_id)
        answer_callback_query(callback_query_id, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        if not rid:
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤ (DB?).")
            return
        send_message(
            chat_id,
            f"‚úÖ –û—Ç–∑—ã–≤ –¥–æ–±–∞–≤–ª–µ–Ω. –ù–æ–º–µ—Ä: #{rid}\n–•–æ—á–µ—à—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –ò–ò-–∞–Ω–∞–ª–∏–∑?",
            reply_markup={
                "inline_keyboard": [
                    [{"text": "üß† –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", "callback_data": f"analyze_review:{rid}"}],
                    [{"text": "‚ùå –ù–µ—Ç", "callback_data": "cancel"}],
                ]
            },
        )
        return

    if data.startswith("analyze_review:"):
        sid = data.split(":", 1)[1]
        if not sid.isdigit():
            answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π ID", show_alert=True)
            return
        rid = int(sid)
        r = db_get_review(rid)
        if not r:
            answer_callback_query(callback_query_id, "–û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
            return
        existing = db_get_analysis_by_review_id(rid)
        if existing and not existing.get("error"):
            answer_callback_query(callback_query_id, "–ö—ç—à")
            brief = format_analysis_brief(existing.get("result_json") or {})
            send_message(
                chat_id,
                f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}:\n\n{brief}",
                reply_markup=analysis_keyboard(existing["id"], include_reanalyze=True, review_id=rid),
            )
            return
        answer_callback_query(callback_query_id, "–ü—Ä–∏–Ω—è—Ç–æ")
        send_message(chat_id, f"–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}‚Ä¶")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, r.get("meta", {}).get("added_by") or chat_id, r["review_text"], r.get("platform") or "unknown", r.get("rating"), rid),
            daemon=True,
        ).start()
        return

    if data.startswith("reanalyze_review:"):
        sid = data.split(":", 1)[1]
        if not sid.isdigit():
            answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π ID", show_alert=True)
            return
        rid = int(sid)
        r = db_get_review(rid)
        if not r:
            answer_callback_query(callback_query_id, "–û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
            return
        answer_callback_query(callback_query_id, "–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—é")
        send_message(chat_id, f"üîÑ –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—é –∞–Ω–∞–ª–∏–∑ –¥–ª—è #{rid}‚Ä¶")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, r.get("meta", {}).get("added_by") or chat_id, r["review_text"], r.get("platform") or "unknown", r.get("rating"), rid),
            daemon=True,
        ).start()
        return

    if data.startswith("find_platform:"):
        platform = data.split(":", 1)[1]
        db_set_session(chat_id, STATE_FIND_RATING, {"platform": platform})
        answer_callback_query(callback_query_id, "–û–∫")
        send_message(
            chat_id,
            "–†–µ–π—Ç–∏–Ω–≥:",
            reply_markup={
                "inline_keyboard": [
                    [{"text": "–í—Å–µ", "callback_data": "find_rating:all"}],
                    [
                        {"text": "‚≠ê1", "callback_data": "find_rating:1"},
                        {"text": "‚≠ê2", "callback_data": "find_rating:2"},
                        {"text": "‚≠ê3", "callback_data": "find_rating:3"},
                        {"text": "‚≠ê4", "callback_data": "find_rating:4"},
                        {"text": "‚≠ê5", "callback_data": "find_rating:5"},
                    ],
                ]
            },
        )
        return

    if data.startswith("find_rating:"):
        rating_value = data.split(":", 1)[1]
        rating = int(rating_value) if rating_value.isdigit() else None
        session = _get_active_session(chat_id)
        if not session:
            answer_callback_query(callback_query_id, "–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
            return
        payload = session.get("payload") or {}
        payload["rating"] = rating
        db_set_session(chat_id, STATE_FIND_DAYS, payload)
        answer_callback_query(callback_query_id, "–û–∫")
        send_message(
            chat_id,
            "–ó–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥?",
            reply_markup={
                "inline_keyboard": [
                    [{"text": "7 –¥–Ω–µ–π", "callback_data": "find_days:7"}],
                    [{"text": "30 –¥–Ω–µ–π", "callback_data": "find_days:30"}],
                    [{"text": "90 –¥–Ω–µ–π", "callback_data": "find_days:90"}],
                ]
            },
        )
        return

    if data.startswith("find_days:"):
        days_value = data.split(":", 1)[1]
        if not days_value.isdigit():
            answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π –ø–µ—Ä–∏–æ–¥", show_alert=True)
            return
        days = int(days_value)
        session = _get_active_session(chat_id)
        payload = session.get("payload") if session else {}
        payload = payload or {}
        payload["days"] = days
        payload["offset"] = 0
        db_set_session(chat_id, STATE_NONE, payload)
        answer_callback_query(callback_query_id, "–ò—â—É")
        send_find_results(chat_id, payload)
        return

    if data.startswith("find_page:"):
        direction = data.split(":", 1)[1]
        session = _get_active_session(chat_id)
        if not session:
            answer_callback_query(callback_query_id, "–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
            return
        payload = session.get("payload") or {}
        offset = int(payload.get("offset") or 0)
        if direction == "next":
            offset += 10
        elif direction == "prev":
            offset = max(0, offset - 10)
        payload["offset"] = offset
        db_set_session(chat_id, STATE_NONE, payload)
        answer_callback_query(callback_query_id, "–û–∫")
        send_find_results(chat_id, payload)
        return

    if data.startswith("open_review:"):
        sid = data.split(":", 1)[1]
        if not sid.isdigit():
            answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π ID", show_alert=True)
            return
        rid = int(sid)
        r = db_get_review(rid)
        if not r:
            answer_callback_query(callback_query_id, "–û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
            return
        answer_callback_query(callback_query_id, "–û—Ç–∫—Ä—ã–≤–∞—é")
        send_message(chat_id, f"#{r['id']} [{r.get('platform') or r['source']}] ‚≠ê{r['rating'] or '-'}\n\n{r['review_text']}")
        return

    if data == "settings:engine":
        answer_callback_query(callback_query_id, "–í—ã–±–æ—Ä –ò–ò")
        send_message(chat_id, "–í—ã–±–µ—Ä–∏ –¥–≤–∏–∂–æ–∫:", reply_markup={"inline_keyboard": [[
            {"text": "DeepSeek (Artemox)", "callback_data": "set_engine:deepseek"},
            {"text": "OpenAI", "callback_data": "set_engine:openai"},
        ], [
            {"text": "Gemini", "callback_data": "set_engine:gemini"},
            {"text": "Grok", "callback_data": "set_engine:grok"},
        ]]})
        return

    if data == "settings:context":
        answer_callback_query(callback_query_id, "–ë–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç")
        _reset_state(chat_id)
        db_set_session(chat_id, STATE_WAIT_CONTEXT, {})
        send_message(chat_id, "–û—Ç–ø—Ä–∞–≤—å –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")
        return

    if data.startswith("set_engine:"):
        engine = data.split(":", 1)[1]
        db_set_setting("ai_engine_override", {"value": engine})
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        send_message(chat_id, f"‚úÖ –î–≤–∏–∂–æ–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {engine}")
        return

    # analysis buttons
    if ":" not in data:
        answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω–∞—è –∫–Ω–æ–ø–∫–∞", show_alert=True)
        return

    action, sid = data.split(":", 1)
    if not sid.isdigit():
        answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π ID", show_alert=True)
        return

    analysis_id = int(sid)
    a = db_get_analysis(analysis_id)
    if not a:
        answer_callback_query(callback_query_id, "–ê–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    obj = a.get("result_json") or {}
    err = a.get("error")

    if err:
        answer_callback_query(callback_query_id, "–ê–Ω–∞–ª–∏–∑ —Å –æ—à–∏–±–∫–æ–π ‚Äî —Å–º–æ—Ç—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ", show_alert=False)

    if action == "json":
        answer_callback_query(callback_query_id, "–û—Ç–ø—Ä–∞–≤–ª—è—é JSON")
        send_message(chat_id, json.dumps(obj, ensure_ascii=False)[:3800])
        return

    public_reply = (obj.get("public_reply") or {}).get("text") if isinstance(obj.get("public_reply"), dict) else None
    complaint_obj = obj.get("complaint") or {}
    complaint_needed = bool(complaint_obj.get("needed"))
    complaint_text = complaint_obj.get("text") if isinstance(complaint_obj, dict) else None
    complaint_count = complaint_obj.get("char_count") if isinstance(complaint_obj, dict) else None

    if action == "reply":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if public_reply:
            send_message(chat_id, f"‚úçÔ∏è –ü—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç:\n\n{public_reply}")
        else:
            send_message(chat_id, "‚ùå –í –∞–Ω–∞–ª–∏–∑–µ –Ω–µ—Ç public_reply.text")
        return

    if action == "complaint":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if not complaint_needed:
            send_message(chat_id, "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ —É—Å–ª–æ–≤–∏—è–º (complaint.needed=false).")
        else:
            extra = f"\n\n–î–ª–∏–Ω–∞: {complaint_count}" if complaint_count is not None else ""
            send_message(chat_id, f"‚ö†Ô∏è –ñ–∞–ª–æ–±–∞:\n\n{complaint_text or '(–ø—É—Å—Ç–æ)'}{extra}")
        return

    if action == "both":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if public_reply:
            send_message(chat_id, f"‚úçÔ∏è –ü—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç:\n\n{public_reply}")
        else:
            send_message(chat_id, "‚ùå –í –∞–Ω–∞–ª–∏–∑–µ –Ω–µ—Ç public_reply.text")

        if not complaint_needed:
            send_message(chat_id, "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ —É—Å–ª–æ–≤–∏—è–º (complaint.needed=false).")
        else:
            extra = f"\n\n–î–ª–∏–Ω–∞: {complaint_count}" if complaint_count is not None else ""
            send_message(chat_id, f"‚ö†Ô∏è –ñ–∞–ª–æ–±–∞:\n\n{complaint_text or '(–ø—É—Å—Ç–æ)'}{extra}")
        return

    answer_callback_query(callback_query_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ", show_alert=True)

# -----------------------------
# Weekly report formatting
# -----------------------------
def format_weekly_report(summary: dict) -> str:
    days = summary.get("days", 7)
    total = summary.get("total", 0)
    with_error = summary.get("with_error", 0)
    avg_rating = summary.get("avg_rating")
    sentiments = summary.get("sentiments", {})
    complaints_needed = summary.get("complaints_needed", 0)
    top_aspects = summary.get("top_aspects", [])
    top_pain_points = summary.get("top_pain_points", [])
    top_recommendations = summary.get("top_recommendations", [])

    lines = []
    lines.append(f"üìä –û—Ç—á—ë—Ç –ø–æ –∞–Ω–∞–ª–∏–∑–∞–º –∑–∞ {days} –¥–Ω–µ–π")
    lines.append(f"–í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {total}")
    lines.append(f"–° –æ—à–∏–±–∫–∞–º–∏: {with_error}")
    if avg_rating is not None:
        lines.append(f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_rating:.2f}")
    lines.append(f"–ñ–∞–ª–æ–± —Ç—Ä–µ–±—É–µ—Ç—Å—è: {complaints_needed}")
    lines.append("")
    lines.append("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:")
    for k in ["negative", "mixed", "neutral", "positive", "unknown"]:
        lines.append(f" - {k}: {sentiments.get(k, 0)}")

    if top_aspects:
        lines.append("")
        lines.append("–¢–æ–ø –∞—Å–ø–µ–∫—Ç–æ–≤ (—á–∞—Å—Ç–æ—Ç–∞):")
        for name, cnt in top_aspects[:10]:
            lines.append(f" - {name}: {cnt}")

    if top_pain_points:
        lines.append("")
        lines.append("–¢–æ–ø pain points:")
        for name, cnt in top_pain_points[:10]:
            lines.append(f" - {name}: {cnt}")

    if top_recommendations:
        lines.append("")
        lines.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–∞–≥—Ä–µ–≥–∞—Ü–∏—è):")
        for name, cnt in top_recommendations[:10]:
            lines.append(f" - {name}: {cnt}")

    return "\n".join(lines)

def format_analysis_brief(result_json: dict) -> str:
    sentiment = result_json.get("sentiment") or {}
    sentiment_label = sentiment.get("label") or "unknown"
    sentiment_score = sentiment.get("score")
    summary = (result_json.get("review_summary") or "").strip()
    lines = [f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment_label}"]
    if sentiment_score is not None:
        lines.append(f"–°–∫–æ—Ä: {sentiment_score}")
    if summary:
        lines.append("")
        lines.append(f"–ö—Ä–∞—Ç–∫–æ: {summary}")
    return "\n".join(lines)

def notify_admins(text: str) -> None:
    for cid in ADMIN_CHAT_IDS:
        send_message(cid, text)

def start_add_review(chat_id: int) -> None:
    _reset_state(chat_id)
    db_set_session(chat_id, STATE_WAIT_REVIEW_TEXT, {})
    send_message(chat_id, "–í—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏ –æ—Ç–ø—Ä–∞–≤—å.\n(–ï—Å–ª–∏ –ø–µ—Ä–µ–¥—É–º–∞–ª ‚Äî –Ω–∞–ø–∏—à–∏ /cancel)")

def start_find_flow(chat_id: int) -> None:
    _reset_state(chat_id)
    db_set_session(chat_id, STATE_FIND_PLATFORM, {})
    send_message(
        chat_id,
        "–ü–ª–æ—â–∞–¥–∫–∞:",
        reply_markup={
            "inline_keyboard": [
                [{"text": "–í—Å–µ", "callback_data": "find_platform:all"}],
                [{"text": "–Ø–Ω–¥–µ–∫—Å", "callback_data": "find_platform:yandex"}],
                [{"text": "2–ì–ò–°", "callback_data": "find_platform:2gis"}],
            ]
        },
    )

def send_find_results(chat_id: int, payload: dict) -> None:
    platform = payload.get("platform")
    rating = payload.get("rating")
    days = int(payload.get("days") or 7)
    offset = int(payload.get("offset") or 0)
    items = db_find_reviews(platform=platform, rating=rating, days=days, limit=10, offset=offset)
    if not items:
        send_message(chat_id, "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    lines = []
    for it in items:
        lines.append(
            f"#{it['id']} | {it['created_at'][:10]} | {it.get('platform') or '-'} | ‚≠ê{it.get('rating') or '-'} | {it['preview']}"
        )
    action_rows = []
    for it in items:
        action_rows.append([
            {"text": f"–û—Ç–∫—Ä—ã—Ç—å #{it['id']}", "callback_data": f"open_review:{it['id']}"},
            {"text": f"–ê–Ω–∞–ª–∏–∑ #{it['id']}", "callback_data": f"analyze_review:{it['id']}"},
        ])
    action_rows.append(
        [
            {"text": "‚¨ÖÔ∏è –ù–∞–∑–∞–¥", "callback_data": "find_page:prev"},
            {"text": "‚û°Ô∏è –î–∞–ª–µ–µ", "callback_data": "find_page:next"},
        ]
    )
    reply_markup = {"inline_keyboard": action_rows}
    send_message(chat_id, "\n".join(lines), reply_markup=reply_markup)

def build_csv_export(rows: List[dict]) -> bytes:
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow([
        "id",
        "created_at",
        "platform",
        "rating",
        "review_text",
        "analysis_created_at",
        "sentiment_label",
        "sentiment_score",
        "public_reply_text",
        "complaint_needed",
        "complaint_text",
    ])
    for row in rows:
        writer.writerow([
            row.get("id"),
            row.get("created_at"),
            row.get("platform"),
            row.get("rating"),
            row.get("review_text"),
            row.get("analysis_created_at"),
            row.get("sentiment_label"),
            row.get("sentiment_score"),
            row.get("public_reply_text"),
            row.get("complaint_needed"),
            row.get("complaint_text"),
        ])
    return output.getvalue().encode("utf-8")

def diag_text() -> str:
    engine = _current_engine()
    prompt_mode = (os.getenv("CX_PROMPT_MODE") or CX_PROMPT_MODE).strip().lower()
    base_url = DEEPSEEK_BASE_URL if engine == "deepseek" else None
    return (
        "–°–∞–º–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:\n"
        f"- webhook_path: {WEBHOOK_PATH}\n"
        f"- engine: {engine}\n"
        f"- prompt_mode: {prompt_mode}\n"
        f"- deepseek_base_url: {base_url}\n"
        f"- deepseek_key_set: {'yes' if DEEPSEEK_API_KEY else 'no'}\n"
        f"- openai_key_set: {'yes' if OPENAI_API_KEY else 'no'}\n"
        f"- gemini_key_set: {'yes' if GEMINI_API_KEY else 'no'}\n"
        f"- db: {'postgres' if DB_OK else 'disabled'}\n"
        f"- openai_sdk: {OPENAI_SDK_AVAILABLE}\n"
    )

# -----------------------------
# Startup
# -----------------------------
db_init()
set_webhook_once()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=PORT)
