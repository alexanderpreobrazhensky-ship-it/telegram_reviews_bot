import os
import json
import logging
import sqlite3
from typing import List, Dict
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters

# ================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==================
TELEGRAM_BOT_TOKEN = "7917601350:AAFG1E7kHKrNzTXIprNADOzLvxpnrUjAcO4"

# ================== –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ù–ï–ô–†–û–°–ï–¢–ò ==================
class OptimizedNLP:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è 1GB RAM"""
    
    def __init__(self):
        self.sentiment_model = None
        self.similarity_model = None
        self.rules_model = None
        self._load_models()
    
    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            print("üß† –ó–∞–≥—Ä—É–∂–∞—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...")
            
            # 1. –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (80MB)
            from transformers import pipeline
            self.sentiment_model = pipeline(
                "sentiment-analysis",
                model="cointegrated/rubert-tiny2-sentiment-balanced",  # –í—Å–µ–≥–æ 80MB!
                device=-1,  # CPU —Ä–µ–∂–∏–º
                truncation=True,
                max_length=256
            )
            print("‚úÖ –ú–æ–¥–µ–ª—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # 2. –ü—Ä–∞–≤–∏–ª–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–±–µ–∑ —Ç—è–∂–µ–ª–æ–π –º–æ–¥–µ–ª–∏)
            self.rules_model = self._init_rules_engine()
            print("‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–∞–≤–∏–ª –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            print("üéØ –í—Å–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π: {e}")
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º")
            self._init_fallback()
    
    def _init_rules_engine(self):
        """–î–≤–∏–≥–∞—Ç–µ–ª—å –ø—Ä–∞–≤–∏–ª —Å ML-–ø–æ–¥–æ–±–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        return {
            'yandex': {
                'prohibited': {
                    '–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': ['–∏–¥–∏–æ—Ç', '–¥—É—Ä–∞–∫', '–º—É–¥–∞–∫', '–∫—Ä–µ—Ç–∏–Ω', '–¥–µ–±–∏–ª', '—Ç—É–ø–∏—Ü–∞'],
                    '–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞': ['–≥–æ–≤–Ω–æ', '—Ö–µ—Ä', '–ø–∏–∑–¥', '–±–ª—è', '–µ–±–∞', '—Ö—É–π'],
                    '—É–≥—Ä–æ–∑—ã': ['—É–±—å—é', '—É–±–∏—Ç—å', '–∏–∑–æ–±—å—é', '–ø–æ–∫–∞–ª–µ—á—É', '—Å–æ–∂–≥—É'],
                    '–∫–ª–µ–≤–µ—Ç–∞': ['–≤–æ—Ä—ã', '–º–æ—à–µ–Ω–Ω–∏–∫–∏', '–æ–±–º–∞–Ω—â–∏–∫–∏', '–∫–∏–¥–∞–ª—ã', '—Ä–∞–∑–≤–æ–¥'],
                    '—Å–ø–∞–º': ['–∫—É–ø–∏—Ç–µ', '–∑–∞–∫–∞–∂–∏—Ç–µ', '–ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ', '—Ä–µ–∫–ª–∞–º–∞', '—Å–∫–∏–¥–∫–∞']
                },
                'weights': {
                    '–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': 0.9,
                    '–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞': 1.0,
                    '—É–≥—Ä–æ–∑—ã': 1.0,
                    '–∫–ª–µ–≤–µ—Ç–∞': 0.8,
                    '—Å–ø–∞–º': 0.6
                }
            },
            '2gis': {
                'prohibited': {
                    '–ª–∏—á–Ω—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': ['–Ω–µ–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω—ã–π', '–±–µ–∑–¥–∞—Ä–Ω—ã–π', '–Ω–µ—É—á–∏', '—Ö–∞–ª—Ç—É—Ä—â–∏–∫–∏'],
                    '–ª–æ–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è': ['–Ω–µ –±—ã–ª–æ', '–Ω–µ –¥–µ–ª–∞–ª–∏', '–æ–±–º–∞–Ω—É–ª–∏', '–∫–∏–Ω—É–ª–∏'],
                    '–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π —Å–ø–∞–º': ['–∑–≤–æ–Ω–∏—Ç–µ', '–ø–∏—à–∏—Ç–µ', '–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç', '–¥–µ—à–µ–≤–ª–µ']
                }
            }
        }
    
    def _init_fallback(self):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –µ—Å–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å"""
        self.sentiment_model = None
        self.rules_model = self._init_rules_engine()
    
    def analyze_sentiment(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é –∏–ª–∏ fallback"""
        if self.sentiment_model:
            try:
                result = self.sentiment_model(text[:512])[0]
                return {
                    'label': 'NEGATIVE' if result['label'] == 'negative' else 
                             'POSITIVE' if result['label'] == 'positive' else 'NEUTRAL',
                    'score': float(result['score']),
                    'source': 'neural'
                }
            except:
                pass
        
        # Fallback –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞
        return self._sentiment_by_rules(text)
    
    def _sentiment_by_rules(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º"""
        text_lower = text.lower()
        
        negative_keywords = ['–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ', '–∫–æ—à–º–∞—Ä', '–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é']
        positive_keywords = ['–æ—Ç–ª–∏—á–Ω–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ', '—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', '—Å–ø–∞—Å–∏–±–æ']
        
        neg_score = sum(1 for word in negative_keywords if word in text_lower)
        pos_score = sum(1 for word in positive_keywords if word in text_lower)
        
        total = max(neg_score + pos_score, 1)
        
        if neg_score > pos_score:
            return {'label': 'NEGATIVE', 'score': neg_score/total, 'source': 'rules'}
        elif pos_score > neg_score:
            return {'label': 'POSITIVE', 'score': pos_score/total, 'source': 'rules'}
        else:
            return {'label': 'NEUTRAL', 'score': 0.5, 'source': 'rules'}
    
    def check_violations(self, text: str, platform: str = 'yandex') -> List[Dict]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π —Å ML-–ø–æ–¥—Ö–æ–¥–æ–º"""
        violations = []
        text_lower = text.lower()
        
        if platform not in self.rules_model:
            platform = 'yandex'
        
        for category, keywords in self.rules_model[platform]['prohibited'].items():
            found_keywords = []
            for keyword in keywords:
                if keyword in text_lower:
                    found_keywords.append(keyword)
            
            if found_keywords:
                confidence = min(0.3 + len(found_keywords) * 0.2, 0.95)
                if platform == 'yandex':
                    confidence *= self.rules_model[platform]['weights'].get(category, 0.7)
                
                violations.append({
                    'category': category,
                    'keywords': found_keywords,
                    'confidence': round(confidence, 2),
                    'severity': 'high' if confidence > 0.8 else 'medium'
                })
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
        if platform == 'yandex':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            words = text.split()
            if len(words) < 10:
                violations.append({
                    'category': '—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–∑—ã–≤',
                    'keywords': [f'{len(words)} —Å–ª–æ–≤'],
                    'confidence': 0.7,
                    'severity': 'low'
                })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ CAPS LOCK
            if len(text) > 10 and sum(1 for c in text if c.isupper()) / len(text) > 0.5:
                violations.append({
                    'category': '–∫—Ä–∏—á–∞—â–∏–π —Ç–µ–∫—Å—Ç (–∫–∞–ø—Å–ª–æ–∫)',
                    'keywords': ['CAPS LOCK'],
                    'confidence': 0.8,
                    'severity': 'medium'
                })
        
        return violations

# ================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==================
print("=" * 60)
print("ü§ñ –ê–ù–ê–õ–ò–ó–ê–¢–û–† –û–¢–ó–´–í–û–í –° –ù–ï–ô–†–û–°–ï–¢–Ø–ú–ò")
print(f"üí™ –ü–∞–º—è—Ç—å: 1 GB RAM | CPU: 2 vCPU")
print("=" * 60)

nlp_engine = OptimizedNLP()

# ================== –ë–ê–ó–ê –î–ê–ù–ù–´–• ==================
def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite –±–∞–∑—ã"""
    conn = sqlite3.connect('reviews.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS analyzed_reviews (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            chat_id INTEGER,
            message_id INTEGER,
            platform TEXT,
            text TEXT,
            sentiment_label TEXT,
            sentiment_score REAL,
            violations_json TEXT,
            complaint_generated BOOLEAN,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS complaints (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            review_id INTEGER,
            platform TEXT,
            complaint_text TEXT,
            status TEXT DEFAULT 'draft',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (review_id) REFERENCES analyzed_reviews (id)
        )
    ''')
    
    conn.commit()
    conn.close()
    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

# ================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ñ–ê–õ–û–ë ==================
def generate_smart_complaint(text: str, violations: List[Dict], platform: str) -> str:
    """–£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∂–∞–ª–æ–±—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Ä—É—à–µ–Ω–∏–π"""
    
    templates = {
        'yandex': {
            'header': "–£–≤–∞–∂–∞–µ–º–∞—è —Å–ª—É–∂–±–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç!\n\n",
            'footer': "\n\n–ü—Ä–æ—Å–∏–º —É–¥–∞–ª–∏—Ç—å –æ—Ç–∑—ã–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –ø. 5.2 –ü—Ä–∞–≤–∏–ª —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤.\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Ö—Ü–µ–Ω—Ç—Ä–∞ ¬´–õ–∏—Ä–∞¬ª",
            'rules': {
                '–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': "–°–æ–¥–µ—Ä–∂–∏—Ç –ª–∏—á–Ω—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤",
                '–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞': "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω—É—é –ª–µ–∫—Å–∏–∫—É",
                '—É–≥—Ä–æ–∑—ã': "–°–æ–¥–µ—Ä–∂–∏—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —É–≥—Ä–æ–∑ –∏ –∑–∞–ø—É–≥–∏–≤–∞–Ω–∏—è",
                '–∫–ª–µ–≤–µ—Ç–∞': "–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç –∑–∞–≤–µ–¥–æ–º–æ –ª–æ–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
                '—Å–ø–∞–º': "–ò–º–µ–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ —Å–ø–∞–º–∞"
            }
        },
        '2gis': {
            'header': "–£–≤–∞–∂–∞–µ–º–∞—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è 2–ì–ò–°!\n\n",
            'footer': "\n\n–ü—Ä–æ—Å–∏–º –ø—Ä–∏–Ω—è—Ç—å –º–µ—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É —Å–æ–≥–ª–∞—à–µ–Ω–∏—é.\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–¢–µ—Ö—Ü–µ–Ω—Ç—Ä ¬´–õ–∏—Ä–∞¬ª",
            'rules': {
                '–ª–∏—á–Ω—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': "–°–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø–æ–¥–æ–±–∞—é—â–∏–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è –≤ –∞–¥—Ä–µ—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤",
                '–ª–æ–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è': "–°–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                '–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π —Å–ø–∞–º': "–ò–º–µ–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π —Ä–µ–∫–ª–∞–º—ã"
            }
        }
    }
    
    tpl = templates.get(platform, templates['yandex'])
    
    # –°–æ–±–∏—Ä–∞–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏—è
    violations_text = ""
    for i, violation in enumerate(violations[:5], 1):
        rule_desc = tpl['rules'].get(violation['category'], violation['category'])
        violations_text += f"{i}. {rule_desc} (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {violation['confidence']:.0%})\n"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∂–∞–ª–æ–±—É
    complaint = f"{tpl['header']}"
    complaint += "–ü—Ä–æ—Å–∏–º —É–¥–∞–ª–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–∑—ã–≤ –ø–æ –ø—Ä–∏—á–∏–Ω–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:\n\n"
    
    if violations_text:
        complaint += "–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è:\n"
        complaint += violations_text + "\n"
    
    complaint += f"–¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞:\n\"{text[:400]}\"\n"
    
    if len(text) > 400:
        complaint += "[... —Ç–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω ...]\n"
    
    complaint += tpl['footer']
    
    return complaint

# ================== –ö–û–ú–ê–ù–î–´ –ë–û–¢–ê ==================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /start"""
    await update.message.reply_text(
        "üß† **–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–∑—ã–≤–æ–≤ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏**\n\n"
        "–Ø –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ—Ç–∑—ã–≤—ã –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏–π –ø—Ä–∞–≤–∏–ª –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç –∏ 2–ì–ò–°.\n\n"
        "üìã **–ö–æ–º–∞–Ω–¥—ã:**\n"
        "/analyze <—Ç–µ–∫—Å—Ç> - –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–∞\n"
        "/yandex <—Ç–µ–∫—Å—Ç> - –∞–Ω–∞–ª–∏–∑ –¥–ª—è –Ø–Ω–¥–µ–∫—Å (2 –∑–≤–µ–∑–¥—ã)\n"
        "/2gis <—Ç–µ–∫—Å—Ç> - –∞–Ω–∞–ª–∏–∑ –¥–ª—è 2–ì–ò–°\n"
        "/stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
        "/demo - –ø—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏\n\n"
        "–ü—Ä–∏–º–µ—Ä:\n"
        "/yandex –£–∂–∞—Å–Ω—ã–π —Å–µ—Ä–≤–∏—Å! –ú–∞—Å—Ç–µ—Ä–∞ –∏–¥–∏–æ—Ç—ã, –≤—Å—ë —Å–ª–æ–º–∞–ª–∏. 2 –∑–≤–µ–∑–¥—ã!"
    )

async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–∞"""
    if not context.args:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã")
        return
    
    text = " ".join(context.args)
    user = update.effective_user
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏
    sentiment = nlp_engine.analyze_sentiment(text)
    violations = nlp_engine.check_violations(text, 'yandex')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    response = f"üß† **–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é:**\n\n"
    response += f"üìä *–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:* {sentiment['label']} ({sentiment['score']:.0%})\n"
    response += f"üìù *–î–ª–∏–Ω–∞:* {len(text.split())} —Å–ª–æ–≤\n\n"
    
    if violations:
        response += f"üö® *–ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ:* {len(violations)}\n"
        for i, v in enumerate(violations[:3], 1):
            emoji = "üî¥" if v['severity'] == 'high' else "üü°" if v['severity'] == 'medium' else "üîµ"
            response += f"{emoji} {v['category']} ({v['confidence']:.0%})\n"
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∂–∞–ª–æ–±—ã
        complaint = generate_smart_complaint(text, violations, 'yandex')
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        conn = sqlite3.connect('reviews.db')
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO analyzed_reviews 
            (chat_id, platform, text, sentiment_label, sentiment_score, violations_json, complaint_generated)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (user.id, 'yandex', text, sentiment['label'], sentiment['score'], 
              json.dumps(violations, ensure_ascii=False), True))
        
        review_id = cursor.lastrowid
        
        cursor.execute('''
            INSERT INTO complaints (review_id, platform, complaint_text)
            VALUES (?, ?, ?)
        ''', (review_id, 'yandex', complaint))
        
        conn.commit()
        conn.close()
        
        response += f"\nüìÑ *–ñ–∞–ª–æ–±–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞!*\n"
        response += f"üÜî ID: `{review_id}`\n"
        response += f"üëÄ –ü—Ä–æ—Å–º–æ—Ç—Ä: /complaint_{review_id}"
    else:
        response += "‚úÖ *–ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ*\n"
        response += "–û—Ç–∑—ã–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∞–≤–∏–ª–∞–º –ø–ª–æ—â–∞–¥–∫–∏"
    
    await update.message.reply_text(response)

async def yandex_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –Ø–Ω–¥–µ–∫—Å (2 –∑–≤–µ–∑–¥—ã)"""
    if not context.args:
        await update.message.reply_text("–£–∫–∞–∂–∏—Ç–µ –æ—Ç–∑—ã–≤ —Å 2 –∑–≤–µ–∑–¥–∞–º–∏")
        return
    
    text = " ".join(context.args)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ 2 –∑–≤–µ–∑–¥
    if any(word in text.lower() for word in ['2 –∑–≤–µ–∑–¥', '–¥–≤–µ –∑–≤–µ–∑–¥', '‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ', '‚≠ê‚≠ê']):
        await analyze_command(update, context)
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∑–≤–µ–∑–¥, –¥–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        context.args = [f"{text} [–æ—Ü–µ–Ω–∫–∞: 2 –∑–≤–µ–∑–¥—ã]"]
        await analyze_command(update, context)

async def show_complaint(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∂–∞–ª–æ–±—É –ø–æ ID"""
    try:
        cmd = update.message.text
        if '_' in cmd:
            review_id = int(cmd.split('_')[1])
        else:
            await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /complaint_1")
            return
        
        conn = sqlite3.connect('reviews.db')
        cursor = conn.cursor()
        cursor.execute('''
            SELECT c.complaint_text, r.platform 
            FROM complaints c
            JOIN analyzed_reviews r ON c.review_id = r.id
            WHERE c.review_id = ?
        ''', (review_id,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            complaint_text, platform = result
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—è–º–∏ (Telegram –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ)
            chunks = [complaint_text[i:i+4000] for i in range(0, len(complaint_text), 4000)]
            
            await update.message.reply_text(f"üìÑ **–ñ–∞–ª–æ–±–∞ –¥–ª—è {platform.upper()}** (ID: {review_id}):")
            
            for i, chunk in enumerate(chunks, 1):
                await update.message.reply_text(f"```\n{chunk}\n```")
            
            await update.message.reply_text(
                "üìã **–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n"
                "1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤—ã—à–µ\n"
                "2. –ù–∞–π–¥–∏—Ç–µ –æ—Ç–∑—ã–≤ –Ω–∞ –ø–ª–æ—â–∞–¥–∫–µ\n"
                "3. –ù–∞–∂–º–∏—Ç–µ '–ü–æ–∂–∞–ª–æ–≤–∞—Ç—å—Å—è'\n"
                "4. –í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã"
            )
        else:
            await update.message.reply_text(f"–ñ–∞–ª–æ–±–∞ #{review_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞: {str(e)}")

async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
    conn = sqlite3.connect('reviews.db')
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM analyzed_reviews")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM analyzed_reviews WHERE complaint_generated = 1")
    with_complaints = cursor.fetchone()[0]
    
    cursor.execute("SELECT platform, COUNT(*) FROM analyzed_reviews GROUP BY platform")
    by_platform = cursor.fetchall()
    
    conn.close()
    
    response = "üìà **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:**\n\n"
    response += f"üßÆ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total}\n"
    response += f"üö® –° –Ω–∞—Ä—É—à–µ–Ω–∏—è–º–∏: {with_complaints}\n"
    response += f"üìä –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {with_complaints/max(total,1)*100:.1f}%\n\n"
    
    if by_platform:
        response += "**–ü–æ –ø–ª–æ—â–∞–¥–∫–∞–º:**\n"
        for platform, count in by_platform:
            response += f"‚Ä¢ {platform.upper()}: {count}\n"
    
    await update.message.reply_text(response)

# ================== –ó–ê–ü–£–°–ö ==================
def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    init_database()
    
    print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞, –∑–∞–ø—É—Å–∫–∞—é –±–æ—Ç–∞...")
    
    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("analyze", analyze_command))
    app.add_handler(CommandHandler("yandex", yandex_command))
    app.add_handler(CommandHandler("2gis", analyze_command))
    app.add_handler(CommandHandler("stats", stats_command))
    app.add_handler(CommandHandler("demo", start_command))
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∂–∞–ª–æ–±
    app.add_handler(MessageHandler(
        filters.Regex(r'^/complaint_\d+$'),
        show_complaint
    ))
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    app.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND,
        lambda u, c: u.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥")
    ))
    
    print("=" * 60)
    print("ü§ñ –ë–û–¢ –ó–ê–ü–£–©–ï–ù –ò –ì–û–¢–û–í –ö –†–ê–ë–û–¢–ï!")
    print("üí¨ –ò—â–∏—Ç–µ –≤ Telegram –∏ –ø–∏—à–∏—Ç–µ /start")
    print("=" * 60)
    
    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()
