import os
import re
import json
import time
import logging
import threading
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional, Tuple

import requests
from flask import Flask, request, jsonify

# -----------------------------
# Logging
# -----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("telegram_reviews_bot")

# -----------------------------
# Optional OpenAI SDK (highly recommended for DeepSeek gateways)
# -----------------------------
try:
    from openai import OpenAI  # type: ignore
    OPENAI_SDK_AVAILABLE = True
except Exception:
    OPENAI_SDK_AVAILABLE = False

# -----------------------------
# Env / Config
# -----------------------------
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN") or os.getenv("TELEGRAM_TOKEN")
if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN (or TELEGRAM_TOKEN) is required")

WEBHOOK_URL = os.getenv("WEBHOOK_URL")
if not WEBHOOK_URL:
    raise ValueError("WEBHOOK_URL is required (e.g. https://xxx.up.railway.app)")

# secret part of webhook path (hook123)
BOT_PATH_SECRET = os.getenv("BOT_PATH_SECRET", "").strip()
if not BOT_PATH_SECRET:
    # fallback: last 12 chars of token (not ideal, but prevents 404)
    BOT_PATH_SECRET = TELEGRAM_BOT_TOKEN[-12:]
    logger.warning("BOT_PATH_SECRET not set. Using fallback based on token suffix.")

WEBHOOK_PATH = f"/webhook/{BOT_PATH_SECRET}"
WEBHOOK_FULL_URL = f"{WEBHOOK_URL.rstrip('/')}{WEBHOOK_PATH}"

PORT = int(os.getenv("PORT", "8000"))

AI_ENGINE = (os.getenv("AI_ENGINE") or "deepseek").strip().lower()  # default deepseek
CX_PROMPT_MODE = (os.getenv("CX_PROMPT_MODE") or "full").strip().lower()  # full|lite

# DeepSeek / Artemox
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY") or os.getenv("DEEPSEEK_KEY")
DEEPSEEK_BASE_URL = (os.getenv("DEEPSEEK_BASE_URL") or "https://api.artemox.com/v1").rstrip("/")
DEEPSEEK_MODEL = os.getenv("DEEPSEEK_MODEL") or "deepseek-chat"
DEEPSEEK_URL = f"{DEEPSEEK_BASE_URL}/chat/completions"

# OpenAI (optional)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = (os.getenv("OPENAI_BASE_URL") or "https://api.openai.com/v1").rstrip("/")
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or "gpt-4o-mini"

# Gemini (optional)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL") or "gemini-2.0-flash"
GEMINI_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"

# Grok/xAI placeholder (optional)
GROK_API_KEY = os.getenv("GROK_API_KEY")
GROK_BASE_URL = (os.getenv("GROK_BASE_URL") or "").rstrip("/")
GROK_MODEL = os.getenv("GROK_MODEL") or "grok-beta"

# Admin allowlist: comma-separated chat_ids
REPORT_CHAT_IDS = os.getenv("REPORT_CHAT_IDS", "").strip()
ADMIN_CHAT_IDS: List[int] = []
if REPORT_CHAT_IDS:
    for x in REPORT_CHAT_IDS.split(","):
        x = x.strip()
        if x:
            try:
                ADMIN_CHAT_IDS.append(int(x))
            except Exception:
                pass

ADMIN_MODE = "allowlist" if ADMIN_CHAT_IDS else "open"

# DB
DATABASE_URL = os.getenv("DATABASE_URL") or os.getenv("DATABASE_PUBLIC_URL") or os.getenv("DATABASE_URL_INTERNAL")

# Cron token (protect /cron/weekly)
CRON_TOKEN = os.getenv("CRON_TOKEN", "").strip()

# Diagnostics token (optional) - if set, /diag/ai requires ?token=
DIAG_TOKEN = os.getenv("DIAG_TOKEN", "").strip()

# Timeouts
TG_TIMEOUT = float(os.getenv("TG_TIMEOUT", "10"))
AI_TIMEOUT = float(os.getenv("AI_TIMEOUT", "40"))

# -----------------------------
# Flask
# -----------------------------
app = Flask(__name__)

# -----------------------------
# Telegram helpers
# -----------------------------
def tg_api(method: str) -> str:
    return f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/{method}"

def send_message(chat_id: int, text: str, reply_markup: Optional[dict] = None) -> None:
    payload = {"chat_id": chat_id, "text": text}
    if reply_markup:
        payload["reply_markup"] = reply_markup
    try:
        r = requests.post(tg_api("sendMessage"), json=payload, timeout=TG_TIMEOUT)
        if r.status_code != 200:
            logger.error("sendMessage failed status=%s body=%s", r.status_code, _redact(r.text[:900]))
    except Exception as e:
        logger.exception("sendMessage exception: %s", e)

def answer_callback_query(callback_query_id: str, text: str = "", show_alert: bool = False) -> None:
    payload = {"callback_query_id": callback_query_id, "text": text, "show_alert": show_alert}
    try:
        r = requests.post(tg_api("answerCallbackQuery"), json=payload, timeout=TG_TIMEOUT)
        if r.status_code != 200:
            logger.error("answerCallbackQuery failed status=%s body=%s", r.status_code, _redact(r.text[:500]))
    except Exception:
        logger.exception("answerCallbackQuery exception")

def _is_admin(chat_id: Optional[int]) -> bool:
    if chat_id is None:
        return False
    if not ADMIN_CHAT_IDS:
        return True  # open mode
    return chat_id in ADMIN_CHAT_IDS

# -----------------------------
# Webhook setup (per process)
# -----------------------------
_webhook_set_once = False
_webhook_lock = threading.Lock()

def set_webhook_once() -> None:
    global _webhook_set_once
    with _webhook_lock:
        if _webhook_set_once:
            return
        _webhook_set_once = True

    try:
        logger.info("Setting webhook: %s", WEBHOOK_FULL_URL)
        r = requests.get(
            tg_api("setWebhook"),
            params={"url": WEBHOOK_FULL_URL},
            timeout=TG_TIMEOUT,
        )
        # 429 —á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç –∏–∑-–∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ ‚Äî –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
        if r.status_code == 200:
            logger.info("setWebhook OK: %s", _redact(r.text[:500]))
        elif r.status_code == 429:
            logger.warning("setWebhook got 429 (ignored): %s", _redact(r.text[:500]))
        else:
            logger.error("setWebhook failed status=%s body=%s", r.status_code, _redact(r.text[:900]))
    except Exception:
        logger.exception("setWebhook exception")

# -----------------------------
# DB layer (psycopg v3 recommended)
# -----------------------------
DB_OK = False

def _db_connect():
    """
    Returns psycopg connection, or None if not configured.
    """
    if not DATABASE_URL:
        return None
    try:
        import psycopg  # type: ignore
        conn = psycopg.connect(DATABASE_URL, autocommit=True)
        return conn
    except Exception as e:
        logger.error("DB connect failed: %s", e)
        return None

def db_init() -> None:
    global DB_OK
    conn = _db_connect()
    if not conn:
        DB_OK = False
        logger.warning("DB init skipped (DATABASE_URL not set or connect failed)")
        return
    try:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS reviews (
                    id BIGSERIAL PRIMARY KEY,
                    source TEXT NOT NULL DEFAULT 'manual',
                    rating INT,
                    review_text TEXT NOT NULL,
                    meta JSONB NOT NULL DEFAULT '{}'::jsonb,
                    created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                );
            """)
            cur.execute("""
                CREATE TABLE IF NOT EXISTS review_analyses (
                    id BIGSERIAL PRIMARY KEY,
                    review_id BIGINT,
                    platform TEXT,
                    rating INT,
                    review_text TEXT NOT NULL,
                    result_json JSONB NOT NULL DEFAULT '{}'::jsonb,
                    error TEXT,
                    model TEXT,
                    engine TEXT,
                    created_by BIGINT,
                    created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                );
            """)
        DB_OK = True
        logger.info("DB init OK (postgres=True)")
    except Exception:
        DB_OK = False
        logger.exception("DB init failed")
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_insert_review(source: str, rating: Optional[int], review_text: str, meta: dict) -> Optional[int]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO reviews (source, rating, review_text, meta) VALUES (%s, %s, %s, %s) RETURNING id",
                (source, rating, review_text, json.dumps(meta, ensure_ascii=False)),
            )
            row = cur.fetchone()
            return int(row[0]) if row else None
    except Exception:
        logger.exception("db_insert_review failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_review(review_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT id, source, rating, review_text, meta, created_at FROM reviews WHERE id=%s", (review_id,))
            row = cur.fetchone()
            if not row:
                return None
            return {
                "id": int(row[0]),
                "source": row[1],
                "rating": row[2],
                "review_text": row[3],
                "meta": row[4] if isinstance(row[4], dict) else (json.loads(row[4]) if row[4] else {}),
                "created_at": str(row[5]),
            }
    except Exception:
        logger.exception("db_get_review failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_list_reviews(n: int = 10, source: Optional[str] = None) -> List[dict]:
    conn = _db_connect()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            if source:
                cur.execute(
                    "SELECT id, source, rating, left(review_text, 140), created_at FROM reviews WHERE source=%s ORDER BY id DESC LIMIT %s",
                    (source, n),
                )
            else:
                cur.execute(
                    "SELECT id, source, rating, left(review_text, 140), created_at FROM reviews ORDER BY id DESC LIMIT %s",
                    (n,),
                )
            rows = cur.fetchall() or []
            out = []
            for r in rows:
                out.append({
                    "id": int(r[0]),
                    "source": r[1],
                    "rating": r[2],
                    "preview": r[3],
                    "created_at": str(r[4]),
                })
            return out
    except Exception:
        logger.exception("db_list_reviews failed")
        return []
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_delete_review(review_id: int) -> bool:
    conn = _db_connect()
    if not conn:
        return False
    try:
        with conn.cursor() as cur:
            cur.execute("DELETE FROM reviews WHERE id=%s", (review_id,))
        return True
    except Exception:
        logger.exception("db_delete_review failed")
        return False
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_insert_analysis(
    review_id: Optional[int],
    platform: Optional[str],
    rating: Optional[int],
    review_text: str,
    result_json: dict,
    error: Optional[str],
    model: str,
    engine: str,
    created_by: Optional[int],
) -> Optional[int]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO review_analyses
                (review_id, platform, rating, review_text, result_json, error, model, engine, created_by)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
                RETURNING id
                """,
                (
                    review_id,
                    platform,
                    rating,
                    review_text,
                    json.dumps(result_json, ensure_ascii=False),
                    error,
                    model,
                    engine,
                    created_by,
                ),
            )
            row = cur.fetchone()
            return int(row[0]) if row else None
    except Exception:
        logger.exception("db_insert_analysis failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_get_analysis(analysis_id: int) -> Optional[dict]:
    conn = _db_connect()
    if not conn:
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(
                "SELECT id, review_id, platform, rating, review_text, result_json, error, model, engine, created_by, created_at FROM review_analyses WHERE id=%s",
                (analysis_id,),
            )
            r = cur.fetchone()
            if not r:
                return None
            return {
                "id": int(r[0]),
                "review_id": r[1],
                "platform": r[2],
                "rating": r[3],
                "review_text": r[4],
                "result_json": r[5] if isinstance(r[5], dict) else (json.loads(r[5]) if r[5] else {}),
                "error": r[6],
                "model": r[7],
                "engine": r[8],
                "created_by": r[9],
                "created_at": str(r[10]),
            }
    except Exception:
        logger.exception("db_get_analysis failed")
        return None
    finally:
        try:
            conn.close()
        except Exception:
            pass

def db_weekly_summary(days: int = 7) -> dict:
    conn = _db_connect()
    if not conn:
        return {"ok": False, "error": "DB not configured"}
    try:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT
                  count(*) as total,
                  count(*) FILTER (WHERE error IS NOT NULL) as with_error
                FROM review_analyses
                WHERE created_at >= now() - (%s || ' days')::interval
                """,
                (days,),
            )
            row = cur.fetchone() or (0, 0)
            total = int(row[0])
            with_error = int(row[1])

            # sentiment distribution (best-effort from stored json)
            cur.execute(
                """
                SELECT result_json
                FROM review_analyses
                WHERE created_at >= now() - (%s || ' days')::interval
                """,
                (days,),
            )
            rows = cur.fetchall() or []
            sentiments = {"negative": 0, "mixed": 0, "neutral": 0, "positive": 0, "unknown": 0}
            complaints_needed = 0
            aspects_counter: Dict[str, int] = {}

            for (rj,) in rows:
                obj = rj if isinstance(rj, dict) else (json.loads(rj) if rj else {})
                s = (obj.get("sentiment") or {}).get("label") or "unknown"
                if s not in sentiments:
                    s = "unknown"
                sentiments[s] += 1

                comp = (obj.get("complaint") or {})
                if comp.get("needed") is True:
                    complaints_needed += 1

                aspects = obj.get("aspects") or []
                if isinstance(aspects, list):
                    for a in aspects:
                        name = (a or {}).get("name")
                        if name and isinstance(name, str):
                            key = name.strip().lower()
                            aspects_counter[key] = aspects_counter.get(key, 0) + 1

            top_aspects = sorted(aspects_counter.items(), key=lambda x: x[1], reverse=True)[:10]

            return {
                "ok": True,
                "days": days,
                "total": total,
                "with_error": with_error,
                "sentiments": sentiments,
                "complaints_needed": complaints_needed,
                "top_aspects": top_aspects,
            }
    except Exception:
        logger.exception("db_weekly_summary failed")
        return {"ok": False, "error": "db_weekly_summary failed"}
    finally:
        try:
            conn.close()
        except Exception:
            pass

# -----------------------------
# Prompt (FULL + LITE)
# -----------------------------
CX_PROMPT_FULL = r"""
–¢–´ ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å –¥–ª—è Telegram-–±–æ—Ç–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ—Ä–≤–∏—Å–∞ (CX/Service Quality). –ë–æ—Ç –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–ª–æ—â–∞–¥–æ–∫ (—Å–µ–π—á–∞—Å: 2–ì–ò–° –∏ –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã), —Å –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–æ–π –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –ú–æ–¥–µ–ª—å –ò–ò –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî DEEPSEEK, –Ω–æ –ª–æ–≥–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê (—Å—Ç—Ä–æ–≥–æ):
1) –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–ª–æ—â–∞–¥–∫—É (2–ì–ò–° / –Ø–Ω–¥–µ–∫—Å) –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞.
2) –î–∞—Ç—å –ì–õ–£–ë–û–ö–ò–ô –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–∞: –ø—Ä–∏—á–∏–Ω—ã, —Å–±–æ–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–ª–µ–º—ã (–Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Å–µ—Ä–≤–∏—Å–∞), —Ä–∏—Å–∫–∏, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏.
3) –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Ç–∑—ã–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º –ø–ª–æ—â–∞–¥–∫–∏ (–ø–æ —á–µ–∫-–ª–∏—Å—Ç—É –Ω–∏–∂–µ).
4) –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Ç–∑—ã–≤ (—Ä–∞–∑–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ/–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ/—Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ).
5) –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –ø–ª–æ—â–∞–¥–∫–∏ –ò–õ–ò —Ä–µ–π—Ç–∏–Ω–≥ < 2 (—Ç.–µ. 1 –∑–≤–µ–∑–¥–∞) ‚Äî –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∂–∞–ª–æ–±—É –Ω–∞ –æ—Ç–∑—ã–≤:
   - –î–ª—è 2–ì–ò–°: —Ç–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã —Å—Ç—Ä–æ–≥–æ ‚â§ 450 —Å–∏–º–≤–æ–ª–æ–≤ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª—ã).
   - –î–ª—è –Ø–Ω–¥–µ–∫—Å–∞: –∂–∞–ª–æ–±–∞ –∫—Ä–∞—Ç–∫–∞—è, –ø–æ –¥–µ–ª—É.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –ø–µ—Ä–µ–¥–∞–Ω–æ; –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã):
- platform: "2gis" | "yandex" | "unknown" (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- rating: 1..5 (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- review_text: —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
- review_date: –¥–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- business_context: –æ–ø–∏—Å–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞/—É—Å–ª—É–≥/—Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∞ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- branch/city: —Ñ–∏–ª–∏–∞–ª/–≥–æ—Ä–æ–¥ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
- meta: –ª—é–±—ã–µ –¥–æ–ø. –ø–æ–ª—è (—è–∑—ã–∫, –∏–º—è –∞–≤—Ç–æ—Ä–∞, —Å—Å—ã–ª–∫–∞, —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ç–≤–µ—Ç –∏ —Ç.–ø.)

–û–ë–©–ò–ï –ü–†–ò–ù–¶–ò–ü–´ –ö–ê–ß–ï–°–¢–í–ê:
- –ù–∏–∫–∞–∫–∏—Ö –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤–æ –≤—Ö–æ–¥–µ.
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Äî —Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≥–∏–ø–æ—Ç–µ–∑—ã + —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
- –¶–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–∞ –¥–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫–∏–º–∏: –¥–æ 12 —Å–ª–æ–≤.
- –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –≤–µ–∂–ª–∏–≤–æ, –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏.
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—É–±–ª–∏–∫—É–π –∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π –ø—É–±–ª–∏—á–Ω–æ ‚Äú–º—ã –ø–æ–¥–∞–¥–∏–º –∂–∞–ª–æ–±—É‚Äù –∏ –Ω–µ —É–≥—Ä–æ–∂–∞–π –∞–≤—Ç–æ—Ä—É.

–®–ê–ì 1. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–õ–û–©–ê–î–ö–ò (–µ—Å–ª–∏ platform –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/unknown)
–í–µ—Ä–Ω–∏:
- platform_detected.value: "2gis" | "yandex" | "unknown"
- confidence 0..1
- signals: 2‚Äì5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
–ï—Å–ª–∏ –Ω–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Äî "unknown" –∏ confidence ‚â§0.4.

–®–ê–ì 2. –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –û–¢–ó–´–í–ê
–°—Ñ–æ—Ä–º–∏—Ä—É–π:
A) review_summary
B) sentiment.label negative/mixed/neutral/positive + score -100..+100
C) emotions 1‚Äì3
D) aspects 3‚Äì8 (name, weight 0..100, evidence)
E) facts_vs_opinions
F) pain_points 1‚Äì5
G) root_cause_hypotheses 1‚Äì3 (process_stage)
H) business_process_flags (—ç—Ç–∞–ø—ã)
I) risks (reputation/ops/finance)
J) recommendations 4‚Äì10 (priority P0/P1/P2, action, expected_effect, effort S/M/L, metric)
K) clarifying_questions 0‚Äì3

–®–ê–ì 3. CHECK-LIST –ù–ê–†–£–®–ï–ù–ò–ô (policy_check)
–í–µ—Ä–Ω–∏:
- has_possible_violations
- possible_violations (category, confidence, evidence)
- notes

2–ì–ò–° —á–µ–∫-–ª–∏—Å—Ç:
1) –Ω–µ –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç/—Å–æ —Å–ª–æ–≤/–¥–∞–≤–Ω–æ >1 –≥–æ–¥–∞
2) —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
3) –¥—É–±–ª–∏–∫–∞—Ç—ã/–∫–æ–ø–∏–ø–∞—Å—Ç (–≥–∏–ø–æ—Ç–µ–∑–∞)
4) –æ—Ç–≤–µ—Ç –Ω–∞ –¥—Ä—É–≥–æ–π –æ—Ç–∑—ã–≤
5) —Ä–µ–∫–ª–∞–º–∞/–Ω–∞–∫—Ä—É—Ç–∫–∞/—Å—Å—ã–ª–∫–∏
6) –∫–∞–ø—Å–ª–æ–∫/—Å–∏–º–≤–æ–ª—ã
7) —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å/—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ
8) –º–∞—Ç/–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è/—É–≥—Ä–æ–∑—ã/–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è
9) –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ–∫—É–º–µ–Ω—Ç—ã/–º–µ–¥.

–Ø–Ω–¥–µ–∫—Å —á–µ–∫-–ª–∏—Å—Ç:
1) –Ω–µ –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç
2) –Ω–µ–≤–µ—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç/–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
3) –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ–∫—É–º–µ–Ω—Ç—ã/–º–µ–¥
4) —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –±–µ–∑ —Å–æ–≥–ª–∞—Å–∏—è (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è)
5) –æ—Ç–∑—ã–≤ –∫–∞–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞
6) —Ä–µ–∫–ª–∞–º–∞/—Å–ø–∞–º/—Å—Å—ã–ª–∫–∏/–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
7) –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–π/–Ω–∞–∫—Ä—É—á–µ–Ω–Ω—ã–π (–≥–∏–ø–æ—Ç–µ–∑–∞)
8) —É–≥—Ä–æ–∑—ã/–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è/18+

–®–ê–ì 4. public_reply
2‚Äì8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –±–µ–∑ –ü–î–Ω, –±–µ–∑ —É–≥—Ä–æ–∑.

–®–ê–ì 5. complaint
complaint.needed=true –µ—Å–ª–∏:
a) rating < 2 (–µ—Å–ª–∏ rating –µ—Å—Ç—å)
–∏–ª–∏ b) violations —Å confidence >=0.6
–∏–ª–∏ c) —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª ‚Äú–Ω–µ –±—ã–ª–æ –≤–∏–∑–∏—Ç–∞‚Äù (–≥–∏–ø–æ—Ç–µ–∑–∞)
–î–ª—è 2–ì–ò–°: complaint.text <= 450 —Å–∏–º–≤–æ–ª–æ–≤ + –≤–µ—Ä–Ω–∏ char_count.

–í–´–•–û–î–ù–û–ô –§–û–†–ú–ê–¢ (–°–¢–†–û–ì–û: –≤–µ—Ä–Ω—É—Ç—å –¢–û–õ–¨–ö–û JSON)
{
  "platform_detected": {"value":"2gis|yandex|unknown","confidence":0.0,"signals":["..."]},
  "review_summary":"...",
  "sentiment":{"label":"negative|mixed|neutral|positive","score":0},
  "emotions":[{"name":"...","intensity":0}],
  "aspects":[{"name":"...","weight":0,"evidence":["..."]}],
  "facts_vs_opinions":{"facts":["..."],"opinions":["..."]},
  "pain_points":[{"item":"...","severity":"low|medium|high","evidence":["..."]}],
  "root_cause_hypotheses":[{"hypothesis":"...","confidence":0.0,"evidence":["..."],"process_stage":"..."}],
  "business_process_flags":[{"stage":"...","issue":"...","why_it_matters":"..."}],
  "risks":[{"type":"reputation|ops|finance","level":"low|medium|high","why":"..."}],
  "recommendations":[{"priority":"P0|P1|P2","action":"...","expected_effect":"...","effort":"S|M|L","metric":"..."}],
  "clarifying_questions":["..."],
  "policy_check":{
    "has_possible_violations":false,
    "possible_violations":[{"category":"...","confidence":0.0,"evidence":["..."]}],
    "notes":"..."
  },
  "public_reply":{"tone":"...","text":"..."},
  "complaint":{"needed":false,"reasons":["..."],"text":"...","char_count":0}
}
"""

CX_PROMPT_LITE = r"""
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –ø–æ —Å—Ö–µ–º–µ:
platform_detected, review_summary, sentiment, emotions, aspects, facts_vs_opinions, pain_points,
root_cause_hypotheses, business_process_flags, risks, recommendations, clarifying_questions,
policy_check, public_reply, complaint.
–ù–∏–∫–∞–∫–∏—Ö markdown, –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Äî –≥–∏–ø–æ—Ç–µ–∑—ã + confidence.
"""

def get_cx_prompt() -> str:
    return CX_PROMPT_LITE if CX_PROMPT_MODE == "lite" else CX_PROMPT_FULL

# -----------------------------
# Redaction
# -----------------------------
def _redact(s: str) -> str:
    if not s:
        return s
    # hide bot token and api keys if accidentally appear
    s = s.replace(TELEGRAM_BOT_TOKEN, "***TG_TOKEN***")
    if DEEPSEEK_API_KEY:
        s = s.replace(DEEPSEEK_API_KEY, "***DEEPSEEK_KEY***")
    if OPENAI_API_KEY:
        s = s.replace(OPENAI_API_KEY, "***OPENAI_KEY***")
    if GEMINI_API_KEY:
        s = s.replace(GEMINI_API_KEY, "***GEMINI_KEY***")
    if GROK_API_KEY:
        s = s.replace(GROK_API_KEY, "***GROK_KEY***")
    return s

# -----------------------------
# AI clients
# -----------------------------
def ai_chat(messages: List[Dict[str, str]]) -> str:
    engine = (os.getenv("AI_ENGINE") or AI_ENGINE).strip().lower()

    if engine in ("deepseek", "deep-seek", "ds"):
        return call_deepseek(messages)

    if engine in ("openai", "gpt"):
        return call_openai(messages)

    if engine in ("gemini", "google"):
        return call_gemini(messages)

    if engine in ("grok", "xai"):
        return call_grok(messages)

    raise RuntimeError(f"Unknown AI_ENGINE: {engine}")

def call_deepseek(messages: List[Dict[str, str]]) -> str:
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("DEEPSEEK_API_KEY not set")

    # 1) Prefer OpenAI SDK if available (often helps with gateways/proxies)
    if OPENAI_SDK_AVAILABLE:
        try:
            client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
            resp = client.chat.completions.create(
                model=DEEPSEEK_MODEL,
                messages=messages,
                temperature=0.2,
                timeout=AI_TIMEOUT,
            )
            text = (resp.choices[0].message.content or "").strip()
            return text
        except Exception as e:
            logger.warning("DeepSeek via OpenAI SDK failed, fallback to requests. err=%s", str(e)[:200])

    # 2) Fallback: requests with browser-like headers
    payload = {
        "model": DEEPSEEK_MODEL,
        "messages": messages,
        "temperature": 0.2,
        "stream": False,
    }
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0 (compatible; telegramreviewsbot/1.0; Railway)",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
        "Connection": "keep-alive",
    }

    resp = requests.post(DEEPSEEK_URL, json=payload, headers=headers, timeout=AI_TIMEOUT)

    body_preview = _redact(resp.text[:900])
    logger.info("DeepSeek status=%s body=%s", resp.status_code, body_preview)

    # Cloudflare / anti-bot HTML
    if "<html" in resp.text.lower() or "just a moment" in resp.text.lower():
        raise RuntimeError(f"DeepSeek gateway returned HTML (likely Cloudflare). status={resp.status_code}")

    resp.raise_for_status()
    data = resp.json()

    choices = data.get("choices") or []
    if not choices:
        return ""
    msg = choices[0].get("message") or {}
    return (msg.get("content") or "").strip()

def call_openai(messages: List[Dict[str, str]]) -> str:
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY not set")

    if OPENAI_SDK_AVAILABLE:
        client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.2,
            timeout=AI_TIMEOUT,
        )
        return (resp.choices[0].message.content or "").strip()

    # fallback requests
    url = f"{OPENAI_BASE_URL}/chat/completions"
    payload = {"model": OPENAI_MODEL, "messages": messages, "temperature": 0.2}
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    resp = requests.post(url, json=payload, headers=headers, timeout=AI_TIMEOUT)
    logger.info("OpenAI status=%s body=%s", resp.status_code, _redact(resp.text[:700]))
    resp.raise_for_status()
    data = resp.json()
    return (data["choices"][0]["message"]["content"] or "").strip()

def call_gemini(messages: List[Dict[str, str]]) -> str:
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY not set")

    # Convert messages to Gemini format (simple)
    joined = "\n".join([f"{m.get('role','user')}: {m.get('content','')}" for m in messages])
    payload = {
        "contents": [{"role": "user", "parts": [{"text": joined}]}]
    }
    headers = {"Content-Type": "application/json", "X-goog-api-key": GEMINI_API_KEY}
    resp = requests.post(GEMINI_URL, json=payload, headers=headers, timeout=AI_TIMEOUT)
    logger.info("Gemini status=%s body=%s", resp.status_code, _redact(resp.text[:700]))
    resp.raise_for_status()
    data = resp.json()

    candidates = data.get("candidates") or []
    if not candidates:
        return ""
    parts = (candidates[0].get("content") or {}).get("parts") or []
    if not parts:
        return ""
    return (parts[0].get("text") or "").strip()

def call_grok(messages: List[Dict[str, str]]) -> str:
    # Placeholder: implement when you have xAI endpoint details
    raise RuntimeError("GROK engine not configured yet (set GROK_BASE_URL/GROK_API_KEY)")

# -----------------------------
# JSON extraction from LLM response
# -----------------------------
def extract_first_json(text: str) -> Tuple[Optional[dict], Optional[str]]:
    """
    Returns (json_obj, error). Tries to parse JSON even if wrapped in text/code fences.
    """
    if not text:
        return None, "empty_ai_response"

    # remove code fences
    cleaned = text.strip()
    cleaned = re.sub(r"^```(?:json)?\s*", "", cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r"\s*```$", "", cleaned)

    # try direct
    try:
        obj = json.loads(cleaned)
        if isinstance(obj, dict):
            return obj, None
        return None, "json_is_not_object"
    except Exception:
        pass

    # try find first {...} block
    start = cleaned.find("{")
    end = cleaned.rfind("}")
    if start != -1 and end != -1 and end > start:
        candidate = cleaned[start:end+1]
        try:
            obj = json.loads(candidate)
            if isinstance(obj, dict):
                return obj, None
            return None, "json_is_not_object"
        except Exception as e:
            return None, f"json_parse_failed: {str(e)[:120]}"

    return None, "no_json_object_found"

# -----------------------------
# CX analyze (build prompt -> call ai -> parse json)
# -----------------------------
def cx_analyze(input_obj: dict) -> Tuple[Optional[dict], str]:
    """
    Returns (parsed_json_or_none, raw_text)
    """
    system_prompt = get_cx_prompt()

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": json.dumps(input_obj, ensure_ascii=False)},
    ]

    raw = ai_chat(messages)
    parsed, err = extract_first_json(raw)
    if parsed is None:
        raise RuntimeError(f"AI returned invalid JSON. err={err}")
    return parsed, raw

# -----------------------------
# Inline keyboard
# -----------------------------
def analysis_keyboard(analysis_id: int) -> dict:
    return {
        "inline_keyboard": [
            [
                {"text": "‚úçÔ∏è –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç", "callback_data": f"reply:{analysis_id}"},
                {"text": "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞", "callback_data": f"complaint:{analysis_id}"},
            ],
            [
                {"text": "üìå –û—Ç–≤–µ—Ç + –∂–∞–ª–æ–±–∞", "callback_data": f"both:{analysis_id}"},
                {"text": "üßæ JSON", "callback_data": f"json:{analysis_id}"},
            ],
        ]
    }

# -----------------------------
# Commands
# -----------------------------
HELP_TEXT = (
    "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
    "/help ‚Äî –ø–æ–º–æ—â—å\n"
    "/myid ‚Äî user_id/chat_id\n"
    "/engine ‚Äî —Ç–µ–∫—É—â–∏–π AI_ENGINE\n"
    "\n"
    "–ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã:\n"
    "/addreview source=yandex|2gis rating=1..5 <—Ç–µ–∫—Å—Ç>\n"
    "/listreviews n=10 [source=yandex|2gis]\n"
    "/review <id>\n"
    "/deletereview <id>\n"
    "/analyzereview <id>\n"
    "/exports csv [n=100]\n"
    "/weeklyreport days=7\n"
    "\n"
    "–ê–Ω–∞–ª–∏–∑:\n"
    "/analyze <—Ç–µ–∫—Å—Ç>\n"
)

def parse_kv_args(text: str) -> Tuple[Dict[str, str], str]:
    """
    Parses leading key=value tokens.
    Returns (kv, rest_text)
    """
    parts = text.strip().split()
    kv: Dict[str, str] = {}
    rest_start = 0
    for i, p in enumerate(parts):
        if "=" in p and not p.startswith("http"):
            k, v = p.split("=", 1)
            if k and v:
                kv[k.strip().lower()] = v.strip()
                rest_start = i + 1
                continue
        break
    rest = " ".join(parts[rest_start:])
    return kv, rest

# -----------------------------
# Background analysis (to keep webhook fast)
# -----------------------------
def background_analyze(chat_id: int, user_id: int, review_text: str, platform_hint: str = "unknown", rating: Optional[int] = None, review_id: Optional[int] = None) -> None:
    engine = (os.getenv("AI_ENGINE") or AI_ENGINE).strip().lower()
    model_name = ""
    if engine == "deepseek":
        model_name = DEEPSEEK_MODEL
    elif engine == "openai":
        model_name = OPENAI_MODEL
    elif engine == "gemini":
        model_name = GEMINI_MODEL
    elif engine == "grok":
        model_name = GROK_MODEL

    input_obj = {
        "platform": platform_hint,
        "rating": rating,
        "review_text": review_text,
        "review_date": None,
        "business_context": None,
        "branch/city": None,
        "meta": {},
    }

    try:
        parsed, raw = cx_analyze(input_obj)

        analysis_id = db_insert_analysis(
            review_id=review_id,
            platform=parsed.get("platform_detected", {}).get("value") if isinstance(parsed.get("platform_detected"), dict) else platform_hint,
            rating=rating,
            review_text=review_text,
            result_json=parsed,
            error=None,
            model=model_name,
            engine=engine,
            created_by=user_id,
        ) or 0

        send_message(chat_id, f"‚úÖ –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤. ID: {analysis_id}", reply_markup=analysis_keyboard(analysis_id))

    except Exception as e:
        err_text = str(e)
        logger.error("AI exception: %s", err_text)
        logger.exception("AI exception traceback")

        # Store error + minimal result_json
        fallback_json = {
            "_error": "AI failed or returned invalid JSON (see logs)",
            "engine": engine,
        }
        analysis_id = db_insert_analysis(
            review_id=review_id,
            platform=platform_hint,
            rating=rating,
            review_text=review_text,
            result_json=fallback_json,
            error=err_text[:800],
            model=model_name,
            engine=engine,
            created_by=user_id,
        ) or 0

        # Human-readable message
        if "Cloudflare" in err_text or "returned HTML" in err_text or "status=403" in err_text:
            msg = "‚ùå AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: —à–ª—é–∑ –≤–µ—Ä–Ω—É–ª HTML/403 (–ø–æ—Ö–æ–∂–µ Cloudflare/–∑–∞—â–∏—Ç–∞). –ù—É–∂–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ /diag/ai –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤/–¥–æ—Å—Ç—É–ø–∞."
        else:
            msg = "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç –ò–ò. –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å –æ—à–∏–±–∫–æ–π. ID: %d\n–ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏ CX_PROMPT_MODE=lite." % analysis_id

        send_message(chat_id, msg, reply_markup=analysis_keyboard(analysis_id))

# -----------------------------
# HTTP routes
# -----------------------------
@app.get("/")
def health():
    set_webhook_once()
    return jsonify({
        "ok": True,
        "status": "running",
        "webhook_path": WEBHOOK_PATH,
        "ai_engine": (os.getenv("AI_ENGINE") or AI_ENGINE).strip().lower(),
        "prompt_mode": (os.getenv("CX_PROMPT_MODE") or CX_PROMPT_MODE).strip().lower(),
        "admin_mode": ADMIN_MODE,
        "db": "postgres" if DB_OK else "disabled",
        "deepseek_url": DEEPSEEK_URL,
        "openai_sdk": OPENAI_SDK_AVAILABLE,
    })

@app.get("/diag/ai")
def diag_ai():
    # optional protection
    if DIAG_TOKEN:
        token = request.args.get("token", "").strip()
        if token != DIAG_TOKEN:
            return jsonify({"ok": False, "error": "forbidden"}), 403

    engine = (os.getenv("AI_ENGINE") or AI_ENGINE).strip().lower()
    prompt_mode = (os.getenv("CX_PROMPT_MODE") or CX_PROMPT_MODE).strip().lower()

    messages = [
        {"role": "system", "content": "Reply with exactly: OK"},
        {"role": "user", "content": "ping"},
    ]
    try:
        raw = ai_chat(messages)
        return jsonify({
            "ok": True,
            "engine": engine,
            "prompt_mode": prompt_mode,
            "deepseek_url": DEEPSEEK_URL if engine == "deepseek" else None,
            "raw_preview": raw[:300],
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "engine": engine,
            "prompt_mode": prompt_mode,
            "deepseek_url": DEEPSEEK_URL if engine == "deepseek" else None,
            "error": str(e)[:700],
        }), 500

@app.get("/cron/weekly")
def cron_weekly():
    if not CRON_TOKEN:
        return jsonify({"ok": False, "error": "CRON_TOKEN not set"}), 400

    token = request.args.get("token", "").strip()
    if token != CRON_TOKEN:
        return jsonify({"ok": False, "error": "forbidden"}), 403

    days = int(request.args.get("days", "7"))
    summary = db_weekly_summary(days=days)
    if not summary.get("ok"):
        return jsonify(summary), 500

    # send to all admins
    sent_to = []
    text = format_weekly_report(summary)
    for cid in ADMIN_CHAT_IDS:
        send_message(cid, text)
        sent_to.append(cid)

    return jsonify({"ok": True, "days": days, "sent_to": sent_to})

@app.post(WEBHOOK_PATH)
def telegram_webhook():
    update = request.get_json(silent=True) or {}
    logger.info("Update: %s", _redact(json.dumps(update, ensure_ascii=False)[:1200]))

    # callback
    if "callback_query" in update:
        cq = update["callback_query"]
        cq_id = cq.get("id", "")
        msg = cq.get("message") or {}
        chat = msg.get("chat") or {}
        chat_id = chat.get("id")
        data = (cq.get("data") or "").strip()

        try:
            handle_callback(chat_id, cq_id, data)
        except Exception:
            logger.exception("handle_callback failed")
            if cq_id:
                answer_callback_query(cq_id, "–û—à–∏–±–∫–∞", show_alert=True)
        return "ok"

    message = update.get("message") or {}
    chat = message.get("chat") or {}
    chat_id = chat.get("id")
    user = message.get("from") or {}
    user_id = user.get("id")
    text = (message.get("text") or "").strip()

    logger.info("Parsed: chat_id=%s user_id=%s text=%r", chat_id, user_id, text[:220])

    if not chat_id or not user_id:
        return "ok"

    # commands
    if text.startswith("/start"):
        send_message(chat_id, "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–∑—ã–≤–æ–≤.\n–ù–∞–ø–∏—à–∏ /help.")
        return "ok"

    if text.startswith("/help"):
        send_message(chat_id, HELP_TEXT)
        return "ok"

    if text.startswith("/myid"):
        send_message(chat_id, f"–í–∞—à ID: {chat_id}")
        return "ok"

    if text.startswith("/engine"):
        send_message(chat_id, f"–¢–µ–∫—É—â–∏–π AI_ENGINE: {(os.getenv('AI_ENGINE') or AI_ENGINE).strip().lower()}")
        return "ok"

    # admin commands
    if text.startswith("/addreview"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        args = text[len("/addreview"):].strip()
        kv, rest = parse_kv_args(args)

        source = (kv.get("source") or "manual").strip().lower()
        rating = kv.get("rating")
        rating_int = int(rating) if rating and rating.isdigit() else None
        review_text = rest.strip()

        if not review_text:
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /addreview source=yandex rating=5 <—Ç–µ–∫—Å—Ç>")
            return "ok"

        rid = db_insert_review(source=source, rating=rating_int, review_text=review_text, meta={"added_by": user_id})
        if not rid:
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤ (DB?).")
            return "ok"

        send_message(chat_id, f"‚úÖ –û—Ç–∑—ã–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: #{rid}\n–ß—Ç–æ–±—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: /analyzereview {rid}")
        return "ok"

    if text.startswith("/listreviews"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        args = text[len("/listreviews"):].strip()
        kv, _ = parse_kv_args(args)
        n = int(kv.get("n", "10"))
        source = kv.get("source")
        items = db_list_reviews(n=n, source=source)

        if not items:
            send_message(chat_id, "–ü–æ–∫–∞ –Ω–µ—Ç –æ—Ç–∑—ã–≤–æ–≤.")
            return "ok"

        lines = []
        for it in items:
            lines.append(f"#{it['id']} [{it['source']}] ‚≠ê{it['rating'] or '-'} ‚Äî {it['preview']}")
        send_message(chat_id, "\n\n".join(lines))
        return "ok"

    if text.startswith("/review"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        parts = text.split()
        if len(parts) < 2 or not parts[1].isdigit():
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /review <id>")
            return "ok"
        rid = int(parts[1])
        r = db_get_review(rid)
        if not r:
            send_message(chat_id, "‚ùå –û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return "ok"
        send_message(chat_id, f"#{r['id']} [{r['source']}] ‚≠ê{r['rating'] or '-'}\n\n{r['review_text']}")
        return "ok"

    if text.startswith("/deletereview"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        parts = text.split()
        if len(parts) < 2 or not parts[1].isdigit():
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /deletereview <id>")
            return "ok"
        rid = int(parts[1])
        ok = db_delete_review(rid)
        send_message(chat_id, "‚úÖ –£–¥–∞–ª–µ–Ω–æ." if ok else "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å.")
        return "ok"

    if text.startswith("/analyzereview"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        parts = text.split()
        if len(parts) < 2 or not parts[1].isdigit():
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /analyzereview <id>")
            return "ok"

        rid = int(parts[1])
        r = db_get_review(rid)
        if not r:
            send_message(chat_id, "‚ùå –û—Ç–∑—ã–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return "ok"

        send_message(chat_id, "–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑...")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, user_id, r["review_text"], r.get("source") or "unknown", r.get("rating"), rid),
            daemon=True,
        ).start()
        return "ok"

    if text.startswith("/weeklyreport"):
        if not _is_admin(chat_id):
            send_message(chat_id, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
            return "ok"

        args = text[len("/weeklyreport"):].strip()
        kv, _ = parse_kv_args(args)
        days = int(kv.get("days", "7"))
        summary = db_weekly_summary(days=days)
        if not summary.get("ok"):
            send_message(chat_id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç—á—ë—Ç (DB?).")
            return "ok"
        send_message(chat_id, format_weekly_report(summary))
        return "ok"

    # /analyze - works for everyone
    if text.startswith("/analyze"):
        analyze_text = text[len("/analyze"):].strip()
        if not analyze_text:
            send_message(chat_id, "–§–æ—Ä–º–∞—Ç: /analyze <—Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞>")
            return "ok"

        send_message(chat_id, "–ü—Ä–∏–Ω—è–ª ‚úÖ –ì–æ—Ç–æ–≤–ª—é –∞–Ω–∞–ª–∏–∑...")
        threading.Thread(
            target=background_analyze,
            args=(chat_id, user_id, analyze_text, "unknown", None, None),
            daemon=True,
        ).start()
        return "ok"

    # If plain text, you can decide to ignore or treat as analyze:
    # send_message(chat_id, "–ù–∞–ø–∏—à–∏ /help. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞: /analyze <—Ç–µ–∫—Å—Ç>")

    return "ok"

# -----------------------------
# Callback handler
# -----------------------------
def handle_callback(chat_id: Optional[int], callback_query_id: str, data: str) -> None:
    if not chat_id:
        answer_callback_query(callback_query_id, "–ù–µ—Ç chat_id", show_alert=True)
        return

    # data = action:analysis_id
    if ":" not in data:
        answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω–∞—è –∫–Ω–æ–ø–∫–∞", show_alert=True)
        return

    action, sid = data.split(":", 1)
    if not sid.isdigit():
        answer_callback_query(callback_query_id, "–ù–µ–≤–µ—Ä–Ω—ã–π ID", show_alert=True)
        return

    analysis_id = int(sid)
    a = db_get_analysis(analysis_id)
    if not a:
        answer_callback_query(callback_query_id, "–ê–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    obj = a.get("result_json") or {}
    err = a.get("error")

    if err:
        answer_callback_query(callback_query_id, "–ê–Ω–∞–ª–∏–∑ —Å –æ—à–∏–±–∫–æ–π ‚Äî —Å–º–æ—Ç—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ", show_alert=False)

    if action == "json":
        answer_callback_query(callback_query_id, "–û—Ç–ø—Ä–∞–≤–ª—è—é JSON")
        send_message(chat_id, json.dumps(obj, ensure_ascii=False)[:3800])
        return

    public_reply = (obj.get("public_reply") or {}).get("text") if isinstance(obj.get("public_reply"), dict) else None
    complaint_obj = obj.get("complaint") or {}
    complaint_needed = bool(complaint_obj.get("needed"))
    complaint_text = complaint_obj.get("text") if isinstance(complaint_obj, dict) else None
    complaint_count = complaint_obj.get("char_count") if isinstance(complaint_obj, dict) else None

    if action == "reply":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if public_reply:
            send_message(chat_id, f"‚úçÔ∏è –ü—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç:\n\n{public_reply}")
        else:
            send_message(chat_id, "‚ùå –í –∞–Ω–∞–ª–∏–∑–µ –Ω–µ—Ç public_reply.text")
        return

    if action == "complaint":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if not complaint_needed:
            send_message(chat_id, "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ —É—Å–ª–æ–≤–∏—è–º (complaint.needed=false).")
        else:
            extra = f"\n\n–î–ª–∏–Ω–∞: {complaint_count}" if complaint_count is not None else ""
            send_message(chat_id, f"‚ö†Ô∏è –ñ–∞–ª–æ–±–∞:\n\n{complaint_text or '(–ø—É—Å—Ç–æ)'}{extra}")
        return

    if action == "both":
        answer_callback_query(callback_query_id, "–ì–æ—Ç–æ–≤–æ")
        if public_reply:
            send_message(chat_id, f"‚úçÔ∏è –ü—É–±–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç:\n\n{public_reply}")
        else:
            send_message(chat_id, "‚ùå –í –∞–Ω–∞–ª–∏–∑–µ –Ω–µ—Ç public_reply.text")

        if not complaint_needed:
            send_message(chat_id, "‚ö†Ô∏è –ñ–∞–ª–æ–±–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ —É—Å–ª–æ–≤–∏—è–º (complaint.needed=false).")
        else:
            extra = f"\n\n–î–ª–∏–Ω–∞: {complaint_count}" if complaint_count is not None else ""
            send_message(chat_id, f"‚ö†Ô∏è –ñ–∞–ª–æ–±–∞:\n\n{complaint_text or '(–ø—É—Å—Ç–æ)'}{extra}")
        return

    answer_callback_query(callback_query_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ", show_alert=True)

# -----------------------------
# Weekly report formatting
# -----------------------------
def format_weekly_report(summary: dict) -> str:
    days = summary.get("days", 7)
    total = summary.get("total", 0)
    with_error = summary.get("with_error", 0)
    sentiments = summary.get("sentiments", {})
    complaints_needed = summary.get("complaints_needed", 0)
    top_aspects = summary.get("top_aspects", [])

    lines = []
    lines.append(f"üìä –û—Ç—á—ë—Ç –ø–æ –∞–Ω–∞–ª–∏–∑–∞–º –∑–∞ {days} –¥–Ω–µ–π")
    lines.append(f"–í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {total}")
    lines.append(f"–° –æ—à–∏–±–∫–∞–º–∏: {with_error}")
    lines.append(f"–ñ–∞–ª–æ–± —Ç—Ä–µ–±—É–µ—Ç—Å—è: {complaints_needed}")
    lines.append("")
    lines.append("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:")
    for k in ["negative", "mixed", "neutral", "positive", "unknown"]:
        lines.append(f" - {k}: {sentiments.get(k, 0)}")

    if top_aspects:
        lines.append("")
        lines.append("–¢–æ–ø –∞—Å–ø–µ–∫—Ç–æ–≤ (—á–∞—Å—Ç–æ—Ç–∞):")
        for name, cnt in top_aspects[:10]:
            lines.append(f" - {name}: {cnt}")

    return "\n".join(lines)

# -----------------------------
# Startup
# -----------------------------
db_init()
set_webhook_once()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=PORT)
